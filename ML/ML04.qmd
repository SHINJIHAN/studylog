---
title: "제목"
format: html
---

> Reporting Date: December. 03, 2025

딥러닝 모델의 학습 과정은 고차원 매개변수 공간에서의 비선형 최적화 문제로 구성되며, 네트워크는 일반적으로 ‘Affine → Batch Normalization → ReLU’의 층 구조를 반복적으로 적용하고 마지막 단계에서 Affine 변환 후 Softmax를 통해 확률적 출력 분포를 생성한다. 이 구조는 표현 학습 과정에서 분산 안정화, 비선형성 확보, 기울기 흐름 유지라는 세 가지 관점에서 수학적으로 정당화된다.

학습 과정의 이론적 핵심 중 하나는 **바이어스-분산 트레이드오프**이다. 바이어스는 모델의 구조적 단순화로 인해 발생하는 체계적 오차이며, 분산은 데이터의 작은 변화에 모델이 과도하게 반응하며 발생하는 민감도이다. 이 두 요소는 역비례적 관계에 있어, 바이어스를 지나치게 줄이기 위해 모델 복잡성을 높이면 분산이 급격히 증가하여 일반화 성능이 악화된다(오버피팅). 반대로 분산을 줄이기 위해 모델을 지나치게 단순화하면 고정적 편향이 커져 언더피팅이 발생한다. 적절한 최적점은 검증 데이터의 경험적 리스크 최소 지점을 찾는 방식으로 설정된다.

오버피팅이 발생하는 상황에서는 모델이 훈련 데이터의 세부적 노이즈 패턴까지 과도하게 학습하는데, 이는 파라미터 수가 데이터에 비해 과도하게 많거나, 데이터 분포의 다양성이 충분치 않을 때 더욱 심화된다. 이를 완화하기 위한 실질적 접근으로는 **상위 다중 정답(top-k) 평가 지표 사용**, **훈련 데이터의 증강**, **범주별 데이터 균형화**, **정규화(regularization)** 등이 있다.

정규화 중에서도 L2 정규화(가중치 감소)는 기하학적 관점에서 파라미터 공간을 L2 볼 안에 구속하는 효과를 갖는다. 손실 함수에 라그랑주 항 형태로 λ‖W‖²가 추가되며, 이는 고차원 공간에서 가중치 벡터의 크기를 제어해 최적점이 과도하게 한 방향으로 치우치지 않도록 한다. 수식적으로는 단순히 항을 더하는 것으로 보일 수 있으나, 실제로는 매개변수 공간의 형태를 바꾸어(implicit geometry alteration) 최적화 경로와 수렴 특성을 근본적으로 변화시키는 역할을 한다.

언더피팅을 해결하기 위해서는 **특징(feature) 확장**, **비선형성이 높은 모델(KNN, SVM, Decision Tree 등)**의 활용, 그리고 **모델 용량 증가**가 효과적이다. 본질적으로 언더피팅은 함수 공간 자체의 표현력이 낮을 때 발생한다.

데이터셋의 규모 또한 모델 성능에 강한 영향을 준다. 데이터가 적으면 분산이 높아지고 신뢰도 낮은 추정이 발생한다. 이를 보완하기 위해 전통적 데이터 증강뿐 아니라, 최근에는 생성형 모델을 통한 고차원적 데이터 증강이 활용된다. 이는 단순 변환 기반 증강보다 데이터 다양성을 보다 풍부하게 확보할 수 있다는 점에서 중요한 의미를 가진다.

드롭아웃(dropout)은 완전 연결 계층(fully connected layer)에서 특정 뉴런을 확률적으로 비활성화하여 특정 패턴에 대한 파라미터 공동 의존성을 줄이는 방식이다. 이는 모델이 특정 경로에 과도하게 적응하는 것을 방지해 일반화 오차를 개선하며, 수학적으로는 앙상블 평균 효과를 근사하는 것으로 해석된다. 단, 드롭아웃은 학습 시에만 적용되고, 추론 단계에서는 비활성화된 뉴런을 포함한 전체 네트워크를 사용한다.

또한, **교차 검증(cross validation)**은 모델의 일반화 오류를 안정적으로 추정하기 위해 데이터셋을 K개의 폴드(fold)로 분할하여 반복적으로 평가하는 방법이다. 이는 단일 분할로 인한 편향을 제거하고 모델의 평균적 성능을 측정하는 데 필수적이다.

종합적으로, 이러한 최적화 기법·정규화 전략·데이터 관리 기법들은 딥러닝에서 안정적인 학습과 일반화 성능 향상의 핵심 요소이며, 실험 환경에서 모델의 성능을 체계적으로 평가하기 위한 기본적 도구들이다.

---

모델링의 목적과 목표 변수의 특성은 평가 지표 선택의 이론적·실무적 정당성을 결정하는 핵심 요소이다. 각 지표는 통계적 특성, 손실 함수의 기하학적 구조, 모델의 오차 감도 등을 반영하고 있으므로, 단순 비교가 아니라 ‘데이터 생성 과정(DSG: Data-Generating Process)’과 ‘목표 함수의 성질’을 고려해 해석해야 한다.

1. **예측·회귀 모델의 성능 평가**
   회귀 문제에서 사용되는 지표들은 대부분 오차의 분포적 성질과 민감도를 달리한다.

   * **MSE(Mean Squared Error)**: 잔차의 제곱을 평균한 값으로, 큰 오차에 대해 제곱 패널티를 부여함으로써 이상치(outlier)에 매우 민감하다. 이는 L2-리스크 최소화와 연결되며, 확률적 관점에서 정규분포 오차 가정에 대한 최대우도추정(MLE)과 동등하다.
   * **RMSE(Root MSE)**: MSE의 제곱근으로 단위를 원래 스케일로 복구한다. 기하학적으로는 L2-거리 기반 손실이며, 곡률이 크기 때문에 경사 기반 최적화에서 강한 페널티를 제공한다.
   * **MAPE(Mean Absolute Percentage Error)**: 상대적 오차 비율을 측정하므로 스케일이 다른 시계열·수요 예측 등에서 많이 사용된다. 다만 목표값이 0에 근접하면 불안정해진다는 결함이 있다.
   * **Weighted Quantile Loss(평균 가중 분위수 손실)**: 분위수 회귀(quantile regression)의 손실로, 비대칭 오차 구조(과소·과대 예측 비용이 다름)를 모델링할 때 적합하다. 수치 예측에서 리스크 기반 의사결정(예: 보험·수요 예측)에 널리 사용된다.
   * **WASE(Weighted Absolute Scaled Error)**: 시계열 예측 평가에서 사용되며, 단순 차분 기반 성능 대비 상대적 향상을 평가할 수 있다.

2. **분류 모델의 성능 평가**
   분류 지표는 클래스 불균형, 임계값(threshold), 비용 민감도에 따라 해석이 크게 달라진다.

   * **Accuracy(정확도)**: 전체 예측 중 맞춘 비율이지만, 클래스 불균형이 존재할 경우 의미가 급격히 저하된다.
   * **Precision(정밀도 = TP/(TP+FP))**: 양성 예측 중 실제로 양성인 비율로, FP에 대한 비용이 큰 문제에서 핵심 지표가 된다.
   * **Recall(재현율 = TP/(TP+FN))**: 실제 양성 중 모델이 탐지한 비율로, FN 비용이 큰 의료·보안 도메인에서 매우 중요하다.
   * **Confusion Matrix(오차 행렬)**: 클래스 간 오차 구조를 직접 파악할 수 있으며, 이후 ROC·PR 커브 분석의 기초가 된다.
   * **F1 Score**: 정밀도와 재현율의 조화평균으로, 두 지표 간 균형이 중요할 때 사용된다. 특히 불균형 데이터에서 모델 선택에 핵심 지표가 될 수 있다.
     분류 문제에서는 단순 지표 나열보다, “어떤 오류가 비용 측면에서 가장 치명적인가?”를 우선적으로 판단해야 한다.

3. **객체 탐지 모델의 성능 평가**
   객체 탐지 문제는 공간적 위치(Localization)와 클래스 분류(Classification)가 동시에 존재하는 복합 구조다.

   * **IoU(Intersection over Union)**: 예측 박스와 실제 박스의 겹침 비율을 나타내는 핵심 지표로, 공간적 정합도(spatial alignment)를 정량화한다. 특정 IoU 임계값(예: 0.5, 0.75 등)에 따라 AP(Average Precision)을 계산하며, 이는 COCO·Pascal VOC 등 주요 벤치마크의 기본 평가 기준이다.

종합하면, 성능 평가는 단순히 지표를 선택하는 과정이 아니라 **문제의 목적 함수, 오차 비용 구조, 데이터 통계적 특성**을 기반으로 이루어져야 하며, 동일 모델이라도 지표 선택에 따라 결론이 달라질 수 있음을 항상 고려해야 한다.

---

클러스터링은 분류의 한 종류이다.
이것은 비지도 학습이다.

이것의 예시는 회원관리서비스에서 주로 쓰인다.
고객을 관리하고 분류해서 등급을 나누고 그에 걸맞는 서비스를 주는 것이다.

이를 전문용어로 CRM이라 한다.

분류 > 세그멘테이션 > 클러스터링으로 좁아지는 형태

그런 그룹을 많이 만들어서 디테일한 서비스를 제공한다면 
이는 좋을 수도 있지만 비용적인 측면이 높을 수 있으니
경영적인 측면에선 덜 디테일한 것이 오히려 실무진 입장에선 좋을 수 있음.

이때 그룹잉의 기준 중 하나인 거리기반 그룹잉이 있다.

하이-인트라-클레스 유사도

로우-인트라-클레스 유사도

둘 중 하나로 데이터 세트를 클래스 구성한다.
이를 통해 클래스 레이블과 클래스 개수를 찾아낸다.

클러스터링 알고리즘 수행 시 선호되는 속성들

1. 시간과 공간적 관점에서의 규모
2. 서로 다른 타입(유형)의 데이터를 다룰 수 있는 능력
3. 입력 파라미터들을 결정하기 위한 최소한의 도메인 지식
4. 잡음과 이상치를 다룰 수 있는지 여부, 또한 판별도 해야 함.
5. 입력 레코드의 순서에 민감하지 않아야 함, 최근 과거 상관없이 섞어서 골고루.
6. 사용자 관점의 제약 조건 반영 여부, 코로나 시기 등.
7. 결과에 대한 해석능력과 사용성, 

거리를 계산할 때, 가장 근접 계산 방법과 가장 멀리 떨어진 계산 방법의 차이는
전향적 계산과 보수적 계산으로 나뉘는 것이다. 이것의 중간인 평균 거리 계산도 있다.
워드 링크잉은 합병괸 클러스터들의 분산을 최소화하려고 한다는 것.

거리 측정 방법의 종류

1. 유클리드 거리(가장 많이 쓰는 방법, 대각선 즉, 직선 거리)
   이것은 항공 네비에서 쓰일 수 있다.
   사이킷런에서 파라미터로 p=1로 줄 수 있다.

2. 맨하튼 거리, 바로 대각선으로 가로지르지 않고 가로 세로 몇 블록인지 가는 방법.
   이는 보통 자동차 네비게이션에서 쓰인다.
   사잇클런에서 파라미터로 p=2로 줄 수 있다.

3. 최대 놈, 점들의 분포를 고려한 거리
   공분산을 고려한 것. 중심이 아니라 데이터의 분포가 곧 가중치가 된다.

4. 마할라노비스 거리

5. 코사인 거리, 문서간 유사도
   자카드 계수(희박한 데이터에 유용), 편집거리(검색창 등)도 있다.
   피어슨 상관계수.
   “문서”든 “영화”든 결국 벡터로 표현할 수 있으며, 유사도는 벡터 간 거리로 계산되므로 문서 유사도 방식 그대로 영화 등 다양한 비정형 데이터 추천·검색·분류에 활용된다.

6. 편집거리의 연산들: 헤밍, 레벤슈타인 거리 등

알고리즘릭하게 하거나 학습을 시켜서 하거나 둘 중 하나일 것이다.

클러스터링 유형

1. 중심 기반(가장 자주 사용하는 방법, 쉬운 개산, 개수 정하기 힘듦)
2. 중간점 기반
3. 밀도 기반
4. 계층적 기반

---

# 03 벡터 변환

영화의 **장르·감독·가격**처럼 서로 다른 속성(이질적 특징)이 **문서 간 유사도**에 사용될 때는, 
모든 속성을 *같은 공간에서 비교 가능하도록 변환*한 뒤 벡터 형태로 통합한다. 

핵심은 **표현 통일 → 벡터화 → 가중 결합 → 유사도 계산**이다.

1. 서로 다른 개념을 “벡터 공간”으로 통일

문서는 텍스트가 아니어도 **모든 특징을 숫자 벡터(feature vector)**로 바꿀 수 있다.

**범주형(장르, 감독)**

* **One-hot encoding**, **Multi-hot encoding**, **Embedding**을 사용
* 예: 장르 = {액션, 드라마, SF}

  * 한 영화가 액션·SF라면 → `[1, 0, 1]`
* 감독도 동일한 방식 → 감독 수가 많으면 embedding 사용

**연속형(가격, 평점, 상영시간)**

* 그대로 사용하되 **정규화(normalization)** 적용
  예: 가격을 0~1 사이로 스케일링

2. 모든 특징을 하나의 대형 벡터로 결합

예시:

| 특징 | 표현                   |
| -- | -------------------- |
| 장르 | `[1, 0, 1, 0, 0]`    |
| 감독 | `[0, 0, 1, 0, 0, …]` |
| 가격 | `0.42`               |
| 평점 | `0.88`               |

→ 최종 문서 벡터:
`[1, 0, 1, 0, 0, | 0, 0, 1, 0, 0, … | 0.42 | 0.88]`

이렇게 하면 “완전히 다른 개념”도 하나의 벡터 안에서 함께 존재할 수 있음.

# 3. 속성별 영향력(중요도)을 조절

속성이 본질적으로 다르기 때문에 **가중치(weight)**를 준다.

예:

* 줄거리 텍스트: 50%
* 장르: 30%
* 감독: 10%
* 가격: 10%

이를 반영하면,

* 감독이 다르다고 해서 문서 유사도가 0이 되는 것을 방지
* 가격 같은 숫자형 특징이 과도하게 영향 주는 것도 방지

4. 결합된 벡터에 **코사인 유사도**를 적용

최종적으로는 두 영화 벡터의 코사인 유사도를 계산:

[
\text{sim}(A, B) = \frac{A \cdot B}{|A||B|}
]

이렇게 하면

* 장르가 비슷하면 해당 부분 벡터가 기여
* 가격·감독이 비슷하면 그 부분이 기여
* 전체적으로 종합된 유사도가 나옴

5. 핵심 정리

* **서로 다른 개념**이어도 → 모두 **동일한 벡터 공간의 차원**으로 변환
* **각 속성을 수치화**한 뒤 하나의 벡터로 결합
* 필요하면 **가중치**를 부여
* 마지막에는 **코사인 유사도**로 비교

---

핵심은 **“서로 다른 정보들을 모두 숫자 벡터로 만들어 
하나의 ‘영화 프로필’로 통합하고, 그 프로필끼리 유사도를 비교한다”**는 점입니다.
이게 가능한 이유는 **모든 종류의 데이터(장르·감독·가격·텍스트 등)는 결국 수치화할 수 있기 때문**입니다.

1. 핵심 1: 모든 속성을 한 줄짜리 숫자 벡터로 만든다

영화마다 **정리된 요약 정보(프로필)**를 하나의 벡터로 만든다고 생각하면 됩니다.

예:

* “액션·SF” → [1, 0, 1]
* “감독 A” → [0, 1, 0, 0]
* “가격 9,000원” → 0.45
* “평점 8.3” → 0.83

→ 결국 하나의 벡터:
`[1, 0, 1, 0, 1, 0, 0, 0.45, 0.83]`

2. 핵심 2: 두 영화 벡터의 거리를 비교하면 ‘비슷한 영화’가 된다

벡터 A와 벡터 B가 비슷하면 → 영화도 비슷하다고 판단. 다르면 → 유사도가 낮다.
즉, **문서(영화) 간 유사도 = 벡터 간 유사도** 이 원리 하나로 모든 속성이 비교 가능해진다.

3. 핵심 3: 활용되는 곳 (실제 사례)

**추천 시스템**

* 사용자가 본 영화와 비슷한 벡터를 가진 영화를 찾아 추천
* 장르·감독·가격·평점 모두 반영된 추천 가능

**콘텐츠 검색**

* “액션이면서 SF 느낌 나는 영화”
  → 장르 벡터와 유사한 영화 자동 추출

**마케팅 타겟팅**

* 특정 가격대 + 특정 감독 선호 + 특정 장르 조합을 가진 영화군 자동 분류

**클러스터링(군집)**

* 영화 전체를 벡터화 → 비슷한 영화끼리 자동 그룹화
* 가격/감독/장르 차이까지 포함해 군집 생성 가능

---

문서 유사도와 “영화 유사도(메타데이터 기반)”가 **완전히 같은 원리**로 작동한다는 점이 핵심입니다.
즉, **문서를 비교하든 영화를 비교하든 결국 ‘특징 벡터 간 거리 비교’라는 한 원리를 공유**합니다.

1. 문서 유사도 계산의 본질

문서 유사도는 일반적으로 다음 절차를 따릅니다.

1. 문서를 **특징 벡터(feature vector)**로 변환

   * 단어를 TF-IDF, BOW, Embedding 등으로 숫자 벡터화
2. 문서 간 **코사인 유사도**를 계산
3. 유사한 문서를 찾음

즉, **문서 → 벡터, 문서 간 유사도 = 벡터 간 유사도** 이 구조입니다.

2. 영화도 “문서 취급”해서 동일한 구조로 비교

영화는 텍스트가 아니지만, 다음 속성들을 모두 **숫자 벡터**로 변환할 수 있습니다.

* 장르
* 감독
* 배우
* 상영시간
* 가격
* 평점
* 줄거리 텍스트(TF-IDF, embedding)

이걸 하나의 벡터로 합치면, **영화 = 문서와 동일한 ‘특징 벡터’가 됨**
따라서 문서 유사도와 완전히 같은 방식으로 비교할 수 있다.

3. 문서 유사도 = 특징 벡터 유사도

영화도 문서도 결국, **“특징 벡터끼리의 거리/유사도 계산”**으로 정의됩니다.

| 비교 대상 | 벡터 만드는 방식            | 유사도 계산  | 결과    |
| ----- | -------------------- | ------- | ----- |
| 문서    | 단어 벡터(TF-IDF 등)      | 코사인 유사도 | 유사 문서 |
| 영화    | 장르/감독/가격/텍스트 등 통합 벡터 | 코사인 유사도 | 유사 영화 |

둘이 100% 동일한 구조입니다.

4. 활용 방식: 문서 유사도와 완전히 동일

문서 유사도가 다음을 가능하게 하듯:

* 비슷한 문서 검색
* 토픽 클러스터링
* 문서 분류
* 유사 문서 추천

영화도 같은 방식으로 활용 가능합니다.

예)

1. 사용자가 본 영화 A → 벡터(A)
2. 전체 영화 벡터 중 벡터(A)와 가장 가까운 영화들 검색
   → **영화 추천 시스템 구현**

즉,

> 문서 추천에서 문서를 “영화”로 바꾸기만 하면 그대로 적용된다.

---