---
title: "제목"
format: html
---

> Reporting Date: November. 12, 2025

# 01 인공신경망
`Artificial Neural Network, ANN`<br>

인간 두뇌의 신경 연결 구조를 수학적으로 모델링한 계산 체계로서, 
입력층(Input Layer), 은닉층(Hidden Layer), 출력층(Output Layer)으로 구성된 계층적 구조를 가진다. 

각 층의 뉴런(neuron)은 **비선형 활성화 함수(activation function)**를 통해 입력 신호를 고차원 표현으로 변환하며, 이를 기반으로 단순한 패턴 인식부터 복잡한 비선형 함수의 근사까지 수행할 수 있다.



**딥 뉴럴 네트워크**
`Deep Neural Network, DNN`
층의 깊이가 증가함에 따라 다단계 표현 학습이 가능해진 구조.

이는 단순한 비선형 변환의 누적이 아니라, 계층적으로 추상화된 특징(hierarchical features)을 점진적으로 학습하는 체계로서, 데이터의 복잡한 구조를 단계적으로 표현하는 고차원적 학습 모델이다.

DNN의 학습은 손실 함수(loss function)를 최소화하기 위해 가중치(weight)와 편향(bias)을 반복적으로 조정하는 최적화 과정이다. 이 과정은 오차 역전파 알고리즘(backpropagation)과 경사하강법(gradient descent)을 기반으로 하며, 네트워크 출력과 실제값의 차이를 계산하여 각 가중치가 오차에 기여한 정도를 추정하고, 이를 반영해 파라미터를 갱신한다.

층이 깊어질수록 모델의 표현력(expressive power)은 급격히 향상되지만, 
동시에 **기울기 소실(vanishing gradient)**, **과적합(overfitting)**, **연산 복잡도(computational complexity)** 등의 문제가 발생한다. 반면, 네트워크의 폭(wide direction)을 확장하면 각 층의 뉴런 수가 증가하여 더 많은 특징(feature) 차원을 학습할 수 있고, 이는 입력 데이터의 다양성과 분류 대상의 복잡성을 반영한다.


따라서 최적의 네트워크 구조 설계는 단순한 경험적 조정(heuristic tuning)을 넘어, 구조적 효율성과 일반화 성능을 동시에 확보하기 위한 **Neural Architecture Search (NAS)**와 같은 자동화된 탐색 기법의 활용으로 발전하고 있다. 이러한 접근은 모델의 성능 향상뿐 아니라, 연산 효율성 및 학습 안정성까지 고려한 체계적 설계를 가능하게 한다.

그러나 이러한 이론적 토대가 확립되기 이전의 초기 신경망은 XOR 문제조차 해결하지 못했다. 

이는 당시의 네트워크가 단일 계층 구조로서, AND, OR와 같은 **선형 분리(linearly separable)** 문제만을 처리할 수 있었기 때문이다. 당시에는 순전파(forward propagation)만 존재하였으며, 역방향으로 오차를 전달해 가중치를 수정하는 역전파(backpropagation) 개념이 없었다.

이를 수작업으로 확인하면 다음과 같다. 입력 ( x_1, x_2 )에 대해 AND 연산의 경우 입력 조합 (0,0), (0,1), (1,0), (1,1)에 대해 출력은 각각 0, 0, 0, 1이 되어야 한다. 이를 ( y = f(\sum w_i x_i) )로 표현할 때, 적절한 가중치 ( w_i ) 설정을 통해 0 또는 1로 분리 가능한 선형 결정 경계를 형성할 수 있다. 그러나 XOR 문제는 이러한 단일 선형 경계로는 분리할 수 없으며, 다층 구조와 비선형 활성화 함수의 결합이 필요하다. 다시 말해, XOR 문제는 비선형적 패턴을 학습하기 위한 **은닉층(hidden layer)**의 필요성을 입증한 대표적 사례이다.

이후 다층 퍼셉트론(Multi-Layer Perceptron, MLP)과 역전파 알고리즘이 도입되면서 신경망은 비선형 함수 근사 능력을 획득하였고, 이는 딥러닝의 초석이 되었다.




**딥러닝(Deep Learning)**은 단순히 층의 수가 많은 신경망을 의미하지 않는다. 이는 데이터의 구조적 특성과 과업 유형(task type)에 따라 네트워크를 설계하고, 학습의 안정성과 효율성을 확보하기 위한 다양한 최적화 기법을 포함하는 고도화된 신경망 패러다임이다. 예를 들어, **합성곱 신경망(Convolutional Neural Network, CNN)**은 지역적 수용 영역(local receptive field)과 가중치 공유(weight sharing) 구조를 통해 이미지 및 시각적 정보의 공간적 특성을 효율적으로 학습하며, **순환 신경망(Recurrent Neural Network, RNN)**은 시계열 데이터의 시간적 종속성(temporal dependency)을 처리하기 위해 내부 상태(hidden state)를 순환적으로 유지하는 구조를 채택한다.

이처럼 딥러닝은 단순히 전통적 ANN의 확장판이 아니라, 데이터의 형태와 과업의 특성에 맞춰 설계된 다양한 아키텍처와 최적화 전략을 결합한 **고차원 지능 시스템(High-Dimensional Intelligent System)**으로 정의된다. 이는 단순한 계산 모델을 넘어, 인간 지각과 사고의 일부 과정을 수학적으로 구현하려는 인공지능의 핵심 접근 방식이라 할 수 있다.

---

# 02 역전파 알고리즘
`Backpropagation`<br>
인공신경망의 학습 과정에서 손실 함수의 기울기를 각 가중치에 대해 효율적으로 계산하기 위해 체인룰(chain rule)을 적용한 미분 기법이다. 이는 네트워크의 출력층에서 계산된 오차를 입력층 방향으로 역전파하여, 각 파라미터가 오차에 미치는 기여도를 정량적으로 평가하고 이를 바탕으로 가중치를 갱신하는 절차로 구성된다.

기본적으로 신경망의 한 층에서 출력 (f)는 다음과 같이 정의된다:
(f = w x + b)
여기서 (w)는 가중치(weight), (x)는 입력(input), (b)는 편향(bias)이다. 이 식을 여러 층으로 확장하면, 각 층의 출력은 이전 층의 출력을 입력으로 받아 순차적으로 변환된다. 즉,
(a^{(l)} = f^{(l)}(w^{(l)} a^{(l-1)} + b^{(l)}))
로 표현되며, 최종 출력층까지의 연속적 변환은 합성 함수의 형태를 가진다.

이때, 손실 함수 (L)에 대해 각 파라미터의 기울기를 구하려면 체인룰을 사용한다. 예를 들어,
(\frac{\partial L}{\partial w} = \frac{\partial L}{\partial f} \cdot \frac{\partial f}{\partial g} \cdot \frac{\partial g}{\partial w})
와 같이 전개할 수 있다. 이 과정은 네트워크의 각 노드(node)를 연산 단위로, 각 변수(variable)를 데이터 흐름 단위로 해석하여 계산 그래프(computational graph)를 통해 효율적으로 수행된다.

결과적으로, 역전파는 출력층에서 발생한 오차를 기반으로 각 층의 가중치가 손실에 미치는 영향을 편미분으로 추적하고, 이를 반대로 전파하여 파라미터를 갱신한다. 

이렇게 얻어진 기울기는 경사하강법(Gradient Descent) 또는 그 변형 알고리즘(Adam, RMSProp 등)에 의해 사용되며, 모델이 손실 함수를 최소화하는 방향으로 학습되도록 한다.

요약하면, 역전파 알고리즘은 다음의 핵심 절차를 따른다:

1. **순전파(Forward Propagation)**: 입력 데이터를 네트워크를 통해 전달하여 출력과 손실을 계산한다.
2. **오차 계산(Error Computation)**: 출력층에서 실제값과 예측값의 차이를 기반으로 손실 함수를 계산한다.
3. **역전파(Backpropagation)**: 체인룰을 적용하여 각 파라미터의 기울기를 계산한다.
4. **파라미터 갱신(Parameter Update)**: 계산된 기울기를 바탕으로 경사하강법을 사용해 가중치와 편향을 갱신한다.

---

## 2.1 문제점

**하나의 가중치만을 따로 떼어 분석하면**<br>
**전체 네트워크의 상호의존적 구조를 반영하지 못한다**는 점이 역전파의 핵심적 난점 중 하나이다.

1. **신경망은 공동 기여 시스템이다**

신경망의 출력은 단일 가중치의 효과가 아니라,<br>
모든 입력 ( x_i )와 가중치 ( w_i ), 그리고 여러 층을 거친 **비선형 합성 함수**의 결과이다.<br>
즉, 각 가중치는 다른 가중치들과의 조합을 통해서만 의미 있는 출력을 만들어낸다.<br>

이 때문에 하나의 가중치만 고립적으로 평가하면,<br>
**다른 가중치들과의 상호작용(interaction)**을 무시하게 되어 실제 영향도를 정확히 알 수 없다.

2. **역전파는 ‘부분 기여’를 계산하는 과정이다**

역전파 알고리즘의 목적은 각 가중치가 **전체 손실(Loss)에 얼마나 기여했는가**를 계산하는 것이다.
이때 체인룰을 이용해, 출력층에서 발생한 오차가 어떻게 각 가중치 방향으로 퍼져나가는지를 추적한다.

즉, $\frac{\partial L}{\partial w_i}$ 는<br>
"모든 다른 파라미터들이 고정되어 있을 때, ( w_i )를 미세하게 변화시켰을 때 손실이 얼마나 변하는가”를 의미한다.<br>

다시 말해, **하나의 가중치 변화가 전체 결과에 미치는 ‘국소적 기여도(local contribution)’**를 구하는 것이며,
이는 전체 맥락에서의 상호작용을 미분의 형태로 부분적으로 포착한 것입니다.

3. **그러나 ‘전체적 상호작용’은 여전히 남는다**

역전파는 개별 가중치의 기울기를 구하되, **그 계산 과정에 이미 모든 다른 가중치와 뉴런의 값이 포함**됩니다.<br>
즉, 수학적으로는 고립된 것이 아니라, 계산 그래프(computational graph) 전체를 거쳐 영향을 받아 나온 결과입니다.<br>
그럼에도 불구하고 다음과 같은 한계가 존재합니다.

* **비선형성(Nonlinearity)** 때문에, 다른 가중치가 조금만 달라져도 각 기울기의 상대적 영향이 크게 바뀐다.
* 따라서 한 시점의 기울기만으로는 “전체 네트워크에서의 근본적 관계”를 완전히 파악할 수 없다.
* 이로 인해 실제 학습에서는 “한 번의 역전파 결과”보다 “다수의 반복(iteration)을 통한 평균적 수렴”이 중요하다.
<br>

결론적으로 하나의 가중치를 따로 본다면 신경망의 다차원 상호작용을 제대로 볼 수 없다.<br>
그러나 역전파는 바로 그 문제를 **부분 미분의 누적 형태로 해결**합니다.<br>

즉, 각 가중치의 기울기를 “다른 파라미터가 고정된 상태에서의 국소적 영향”으로 계산하고,<br>
이를 전체 그래프를 따라 합성함으로써, 전체 시스템이 함께 조정되도록 하는 것입니다.

결국, **하나의 가중치는 단독으로는 의미가 없고**,<br>
오직 “네트워크 전체에서의 미분적 상호작용” 속에서만 의미를 가집니다.

이 점이 신경망이 선형 모델과 본질적으로 다른 이유이며,<br>
딥러닝 학습이 단순한 회귀(regression)가 아닌 **비선형적 협조 최적화(non-linear cooperative optimization)**라는 점을 보여준다.

---

## 2.2 해결 방안
역전파 + 경사하강법 작동원리<br>

1. **역전파의 순서적 기울기 계산**

출력층에서 손실이 계산된 후, 그 오차를 **뒤로 거슬러 올라가며**(backward)<br>
각 층의 가중치가 손실에 어떤 영향을 미치는지를 따져봅니다.<br>

즉,

* 마지막 층부터 오차의 영향을 계산하고,
* 그 결과를 이전 층의 가중치로 전달하며,
* 각 가중치의 변화 방향(∂L/∂w)을 구합니다.

이게 바로 **chain rule**을 층별로 적용하는 과정입니다.

2. **경사하강법(Gradient Descent)**

각 가중치의 기울기(∂L/∂w)는 “이 방향으로 가면 손실이 증가한다”를 의미합니다.
따라서 반대 방향(−∂L/∂w)으로 이동하면 손실이 감소합니다.
이를 수식으로 표현하면:
[
w_{new} = w_{old} - \eta \frac{\partial L}{\partial w}
]
여기서 (\eta)는 학습률(learning rate)로, 이동 속도를 조절합니다.

즉, 각 가중치는 “에러가 줄어드는 방향으로” 조금씩 움직이며, 이 과정이 전체 네트워크에서 동시에 일어납니다.

3. **순차적 파라미터 갱신**

하나의 가중치 ( w_i )를 업데이트할 때는, 그 시점의 다른 파라미터를 **임시로 고정한 상태**로 취급합니다.
즉, 한 번의 역전파에서는 모든 가중치를 동시에 업데이트하되,
각각은 “현재 다른 값들이 고정되어 있다”는 전제 하에서 계산된 기울기에 따라 움직입니다.

이 점에서 **동시적이면서도 독립적인 최적화 단위**가 형성됩니다.
그 후, 전체 네트워크의 파라미터가 한 번에 갱신되며 다음 반복(iteration)으로 넘어갑니다.

---

## 2.3. 예제: 시그모이드의 연산 흐름 구조

시그모이드 함수
$$
g(z) = \frac{1}{1 + e^{-z}}
$$

를 계산 그래프로 풀어쓰면, 다음과 같은 일련의 연산 노드로 표현됩니다.

$$
z → ( * -1 ) → exp → ( +1 ) → ( 1/x ) → g
$$

즉,

1. 입력값 ( z )에
2. 음수를 곱하고( * -1 ),
3. 지수함수를 취하고( exp ),
4. 1을 더하고( +1 ),
5. 역수를 취하면( 1/x )
   결과적으로 시그모이드 출력 ( g )가 나옵니다.

이처럼 단순한 하나의 수식도 **여러 개의 연산 노드로 분해**되어,
각 노드에서 미분(기울기)이 계산되고 역전파될 수 있도록 구성됩니다.

1. 복잡한 신경망 = 수식의 확장적 노드화

신경망이 복잡해진다는 것은<br>
결국 “이러한 단순한 연산 노드들이 수천, 수만 개로 연결되어 합성된 형태”를 의미합니다.

즉,

* **층이 깊을수록** 합성 함수의 깊이가 늘어나고,
* **뉴런 수가 많을수록** 병렬적인 연산 노드가 많아지며,
* 전체 네트워크는 거대한 계산 그래프(computational graph)로 확장된다.

이 그래프 상에서 역전파는 체인룰을 적용하여,<br>
출력 노드에서 입력 노드로 기울기를 **노드 단위로 전파(backpropagate)** 한다.<br>

2. 직관적으로 보면 신경망의 “복잡성”은 사실 **수학적 표현의 압축 정도**입니다.

즉,

* 수식으로는 간단히 적힌 ( g(f(h(x))) ) 같은 표현이,
* 실제 계산 단계에서는 수십 개의 노드로 세분화되어 구현됩니다.

따라서, 복잡해 보이는 신경망도 결국 “단순한 기본 연산들의 반복적 조합”이며,
그 조합을 **노드 그래프 형태로 펼쳐놓은 것**이 바로 신경망 구조입니다.

---

예 — hypothesis = tf.sigmoid(tf.matmul(L2, W2) + b2) 같은 표현을 
TensorFlow 코드·계산 그래프·TensorBoard 이미지로 웹에서 쉽게 찾을 수 있습니다.

권장 이미지 유형
코드 스니펫과 간단 다이어그램(활성화 함수 흐름).
TensorBoard로 그린 연산 그래프(MatMul → Add(b) → Sigmoid).
계산 그래프의 노드(곱셈·덧셈·비선형 연산) 시각화 예시.

---

## 2.4 해결 방법2

1. 순전파(Forward Propagation)

먼저 신경망은 입력 데이터를 받아 **층을 따라 순방향으로 연산**을 수행합니다.

즉,
$$
x \rightarrow (W_1, b_1) \rightarrow L_1 \rightarrow (W_2, b_2) \rightarrow L_2 \rightarrow \cdots \rightarrow \hat{y}
$$

* $\hat{y}$: 예측값(hypothesis)

이 단계에서는 단지 "현재 가중치로 계산된 결과"를 내는 것뿐입니다.

2. 역전파(Backpropagation)

출력값이 실제 정답 (y)와 다르면 손실 함수 (L(y, \hat{y}))가 커집니다.<br>
이때 **오차를 역방향으로 전파**하여 각 가중치 (w)가 오차에 미친 영향을 계산하고,<br>
그에 따라 가중치를 **오차가 줄어드는 방향으로 미세하게 수정**합니다.

즉,
$$
w := w - \eta \frac{\partial L}{\partial w}
$$

이 과정을 데이터셋의 각 샘플(혹은 배치)에 대해 반복하면서 학습이 진행됩니다.

3. 대규모 데이터가 필요한 이유

오류를 줄이기 위해서는 **다양한 입력 상황**을 학습해야 합니다.<br>
데이터가 많을수록 네트워크는

* 특정 패턴에 과적합되지 않고,
* 전체 분포의 일반적 경향을 학습할 수 있습니다.

즉, 대규모 데이터는 가중치가 **균형 있게 조정되도록** 도와주며,<br>
이는 결국 일반화 능력(generalization)을 향상시킵니다.

4. 가중치 변화 폭의 수렴

학습이 진행될수록

* 손실이 줄어들고,
* 기울기(gradient)의 크기도 점점 작아집니다.

이로 인해 가중치의 변동 폭은 점점 감소하며,<br>
결국 오차가 거의 변하지 않는 **수렴 상태**에 도달합니다.

이때 각 가중치의 분포는 무작위 초기화 상태에서 점차 안정된 정규분포 형태로 가까워집니다.<br>
이는 확률론적으로 “많은 데이터 샘플에 의해 평균적으로 조정된 결과”이기 때문입니다.<br>

5. 테스트 데이터로 검증

훈련(Training) 과정에서 사용되지 않은 **테스트 데이터(Test set)**를 이용해<br>
학습된 모델이 새로운 데이터에서도 잘 작동하는지 검증합니다.<br>

이 과정을 통해 **정확도(accuracy), 손실(loss), 과적합 여부(overfitting)** 등을 평가할 수 있습니다.

---

# 03 딥러닝 모델의 일반적인 학습·활용 흐름

1. **데이터 준비**

   * 가능한 범용(대표성 있는) 데이터셋을 수집합니다.
   * 노이즈 제거, 결측치 처리, 정규화 등 **정제·전처리** 과정을 거칩니다.

2. **데이터 분할**

   * 데이터를 **훈련(train)**, **검증(validation)**, **테스트(test)** 용으로 분리합니다.
   * 훈련용은 모델 학습에, 검증용은 하이퍼파라미터 조정에, 테스트용은 최종 평가에 사용됩니다.

3. **모델 학습**

   * 훈련 데이터로 신경망을 학습시키고,
   * 검증 데이터를 이용해 과적합을 방지하며 모델을 조정합니다.

4. **사전학습(Pre-training)**

   * 최근에는 이 과정을 대규모 데이터와 연산 자원을 활용해<br>
    **미리 학습된 모델(Pre-trained model)** 로 구축합니다.
   * 이렇게 만들어진 모델은 **전이학습(Transfer Learning)** 을 통해 
    다른 사용자가 자신의 데이터에 맞게 재학습(fine-tuning) 할 수 있다.

    일반적으로 **범용적 특징을 학습하는 방향**으로 진행됩니다.<br>
    즉, 특정 과제 하나에 집중하지 않고, 가능한 한 **많은 데이터와 다양한 패턴을 포괄**하도록 설계됩니다.

   **방향: 일반적 패턴 학습**

   * 모델은 “고양이 인식” 같은 구체적 과제가 아니라,
    **시각·언어·음성 등에서 공통적으로 나타나는 일반 구조**를 학습합니다.
   * 예: 이미지 모델은 “모서리, 질감, 색 대비” 같은 기본 시각적 특징을,
        언어 모델은 “문법, 어순, 의미 관계” 같은 일반 언어 규칙을 익힙니다.

   **이유: 효율성과 재사용성**

   * **학습 효율**: 모든 사용자가 처음부터 대규모 학습을 수행하는 것은 비효율적이므로,
    공통 패턴을 미리 학습시켜 두면 이후엔 적은 데이터로도 빠르게 성능을 낼 수 있습니다.
   * **전이 가능성**: 범용적 특징을 배우면, 이후 특정 과제(예: 감정 분석, 질병 분류)에
    일부 가중치만 미세조정(fine-tuning)하여 쉽게 적응할 수 있습니다.

   **결과적으로**

   * 사전학습은 “넓게 → 얕게” 학습하는 과정이며,
   * 전이학습은 “좁게 → 깊게” 구체화하는 과정입니다.

    즉, **사전학습은 공통 기반을 다지는 단계**,
    **전이학습은 목적에 맞게 세부 조정을 하는 단계**입니다.

---

* **뒤쪽(출력층 근처)부터 조정하는 이유**:
  뒤로 갈수록 네트워크가 **더 구체적이고 과제 특화된 특징**을 표현합니다.
  따라서 전이학습 시에는 이 부분만 미세하게 조정해도 충분히 새로운 과제에 적응할 수 있습니다.

* **앞쪽(입력층 근처)을 수정하지 않는 이유**:
  초기층은 대부분의 데이터(이미지, 텍스트 등)에서 **공통적으로 나타나는 일반적 특징**을 이미 잘 학습하고 있기 때문입니다.
  이 부분을 건드리면 오히려 기존의 범용적 표현력이 손상될 수 있습니다.

* **그러나**,
  충분한 데이터, 연산 자원(GPU 등), 시간, 그리고 안정적인 학습 설계가 가능하다면
  **앞단부터 전체 네트워크를 재학습(fine-tuning)** 하는 것이 성능 면에서는 더 이상적입니다.
  이는 기존 가중치를 초기값으로 삼아, 모델 전체가 새로운 도메인에 맞게 완전히 재적합되는 방향입니다.

---

### **TensorFlow**

* **Google이 개발한 딥러닝 프레임워크(저수준)**.
* 수학 연산 그래프를 직접 구성하고, GPU/TPU에서 최적화된 학습을 수행.
* 내부적으로 매우 강력하지만 코드가 복잡하고 구현 난이도가 높음.

### **Keras**

* **TensorFlow 위에서 동작하는 고수준 API**.
* 직관적인 코드로 모델 설계·학습·평가를 쉽게 수행할 수 있게 함.
* 초기에는 독립 프레임워크였으나, 현재는 **TensorFlow에 통합(`tf.keras`)** 되어 표준 인터페이스로 사용됨.
* 즉, **TensorFlow의 고급 래퍼(wrapper)** 역할.

### **PyTorch**

* **Facebook(현재 Meta)** 가 개발한 프레임워크로, TensorFlow보다 **동적 계산 그래프**(Dynamic Graph)를 지원.
* 직관적이며 Python 코드와 유사하게 동작하므로 **연구·프로토타입 개발에 적합**.
* 최근에는 TensorFlow보다 산업·연구 양쪽에서 더 많이 쓰이는 추세.

### 정리 비교

| 구분         | 주요 개발사 | 그래프 방식                | 추상화 수준 | 대표 용도        |
| ---------- | ------ | --------------------- | ------ | ------------ |
| TensorFlow | Google | 정적(Static) → 동적 혼합 지원 | 중간     | 대규모 배포, 산업용  |
| PyTorch    | Meta   | 동적(Dynamic)           | 중간~고   | 연구, 실험, 학습   |
| Keras      | Google | TensorFlow 기반         | 가장 고수준 | 교육, 빠른 프로토타입 |

결론적으로,

> **“TensorFlow → Keras”** 는 상하관계(저수준 ↔ 고수준)이고,
> **“TensorFlow ↔ PyTorch”** 는 경쟁·대체 관계입니다.
> 따라서 ‘고도화된 순서’라기보다 **사용자 친화성과 추상화 수준이 높아진 방향**으로 이해하는 것이 맞습니다.

---

# 02

1. **배치 경사하강법 (Batch Gradient Descent)**

* 전체 데이터셋을 **한 번에** 사용하여 손실 함수의 기울기를 계산.
* 즉, 한 epoch(모든 데이터 1회 학습)마다 **한 번의 가중치 갱신**만 수행.
* 정확하지만 계산량이 매우 크며, 대규모 데이터에서는 비효율적.

2. **확률적 경사하강법 (Stochastic Gradient Descent, SGD)**

* 전체 데이터 중 **하나의 샘플만(random)** 선택하여 매번 가중치를 갱신.
* 즉, 데이터 1개 → 순전파 → 역전파 → 가중치 갱신.
* 계산이 빠르지만, 매번의 갱신이 불안정하고 진동(노이즈)이 많음.

3. **미니배치 경사하강법 (Mini-batch Gradient Descent)**

* 위 두 방법의 절충안.
* **배치**와 **확률적(SGD)** 사이에 위치한 **별도의 변형(variation)**입니다.
* 즉, “하위 요소”가 아니라 **같은 계열의 또 다른 종류**입니다.
* 전체 데이터에서 **랜덤하게 일정 크기(batch size)의 샘플 묶음**을 선택하여 한 번의 갱신을 수행.
* GPU의 병렬 행렬 연산에 최적화되어 있어 **가장 일반적으로 사용**됨.
* “배치 경사하강법”이라 할 때 보통 이 방식을 의미하는 경우가 많음.

1. **GPU 연산의 역할**

* 미니배치는 `행렬 연산` 단위로 묶이므로, GPU의 **병렬 처리 성능**을 최대한 활용 가능.
* 따라서 학습 속도가 대폭 향상됨.

| 방식               | 데이터 사용 | 연산 속도 | 안정성    | 실제 사용                |
| ---------------- | ------ | ----- | ------ | -------------------- |
| 배치(Batch)        | 전체     | 느림    | 매우 안정적 | 거의 안 씀 (대규모 데이터 비효율) |
| 확률적(SGD)         | 1개     | 매우 빠름 | 불안정    | 드묾                   |
| 미니배치(Mini-batch) | 일부 묶음  | 빠름    | 안정적    | **표준**               |


| 구분                      | 사용 데이터 크기 | 특징          | 관계                  |
| ----------------------- | --------- | ----------- | ------------------- |
| **Batch GD**            | 전체 데이터    | 매우 안정적, 느림  | 가장 기본형              |
| **Stochastic GD (SGD)** | 1개 샘플     | 매우 빠름, 불안정  | Batch GD의 확률적 형태    |
| **Mini-batch GD**       | 일부 샘플 묶음  | 속도와 안정성의 균형 | **Batch와 SGD의 중간형** |

**관계를 비유로 보면**

* **Batch**: 전체 학생의 시험 평균을 계산 → 정확하지만 오래 걸림.
* **SGD**: 학생 한 명의 점수만 보고 평균을 추정 → 빠르지만 들쭉날쭉.
* **Mini-batch**: 학생 10명 단위로 묶어 평균 → 속도와 정확성의 균형.

즉, 미니배치는 **두 극단(전체 vs 단일)의 절충형**이지,
둘 중 하나의 하위 개념이 아닙니다.

**수식적 관점**

손실 함수 ( J(\theta) )의 기울기를 구할 때:

* **Batch:**
  (\nabla J(\theta) = \frac{1}{m}\sum_{i=1}^{m}\nabla L(x_i, y_i; \theta))

* **SGD:**
  (\nabla J(\theta) = \nabla L(x_i, y_i; \theta)) (단일 샘플)

* **Mini-batch:**
  (\nabla J(\theta) = \frac{1}{|B|}\sum_{i \in B}\nabla L(x_i, y_i; \theta))
  (B는 랜덤하게 선택된 샘플 집합)

---

1. 에폭(Epoch)
전체 학습 데이터셋이 **한 번 모두 신경망을 통과한 횟수**를 의미합니다.

* 데이터셋 전체를 미니배치 단위로 쪼개서
* 각 배치를 순차적으로 학습시킨 뒤,
* **모든 배치를 1회 처리 완료하면 → 1에폭(epoch)** 이 됩니다.

2. 왜 미니배치에서 중요해졌나?

배치 경사하강법에서는

* 한 번의 학습(기울기 계산) = 모든 데이터 사용 → 사실상 “1에폭 = 1회 학습”이었습니다.
  그래서 **에폭이라는 개념이 크게 필요하지 않았습니다.**

반면 **미니배치 방식**에서는

* 전체 데이터를 여러 묶음(batch)으로 나누어 학습하므로
* 한 번의 학습이 데이터 전체를 보지 않습니다.
  따라서 “전체 데이터를 한 번 다 돌렸는가?”를 **추적하기 위한 지표로 ‘에폭’이 등장**한 것입니다.

3. 예시로 보면

데이터가 10,000개이고,
배치 크기(batch size)가 100이면,

* 한 에폭 = 10,000 / 100 = **100번의 미니배치 업데이트**로 구성됩니다.
* 에폭이 10이라면 → 총 **1,000번(=100×10)** 가중치 갱신이 일어납니다.

4. 스텝(Step)

* 실제로 **한 번의 가중치 업데이트**를 의미합니다.
* 따라서
  $$
  \text{steps per epoch} = \frac{\text{데이터 개수}}{\text{batch size}}
  $$

예:
10,000개 데이터, batch size = 100 →
1 epoch = 100 steps,
10 epoch 학습 = 1,000 steps.

---

**모든 데이터가 최소 한 번은 학습에 사용되도록 보장하기 위한 개념**입니다.

1. 미니배치의 확률적 샘플링 문제

미니배치 경사하강법에서는 전체 데이터셋에서

* **랜덤하게 일부 샘플(batch)**을 뽑아 학습합니다.
* 하지만 완전히 랜덤하게만 뽑으면,

  * 어떤 데이터는 여러 번 선택되고
  * 어떤 데이터는 한 번도 선택되지 않을 가능성이 생깁니다.

이러면 학습이 **데이터 전체 분포를 제대로 반영하지 못하게** 됩니다.

2. 이를 해결하기 위한 개념이 ‘에폭(Epoch)’

그래서 학습 과정에서는 보통 다음과 같이 진행합니다:

1. 전체 데이터셋을 한 번 **셔플(shuffle)** 한다.
2. 셔플된 데이터를 **미니배치 단위로 나눈다.**
3. 나뉜 모든 배치를 한 번씩 학습시킨다. → **이게 1에폭**
4. 다음 에폭에서는 다시 셔플하여 **새로운 확률적 조합**으로 배치를 구성.

이렇게 하면,

* 각 데이터는 에폭당 **정확히 한 번씩 학습에 참여**,
* 여러 에폭이 반복되며 **데이터 전체 분포를 다양하게 반영**할 수 있게 됩니다.

3. 에폭은 “샘플링 균형의 최소 단위”

> * 미니배치: 데이터 일부를 한 번 학습시키는 단위
> * 에폭: **모든 데이터가 최소 한 번 학습에 포함되었는지 보장하는 단위**

이 두 개념이 결합되어야

* 학습 효율성(속도)과
* 데이터 다양성(일반화 성능)을 동시에 확보할 수 있습니다.

---

1. 확률적 경사하강법(SGD)의 장점

* 무작위성(Randomness) 때문에 **지역 최적해(local minimum)**에서 빠져나올 가능성이 높습니다.
* 큰 데이터셋에서도 **빠른 업데이트**가 가능해 효율적입니다.

2. 그러나 한계도 명확합니다

* 매번 소수의 샘플만으로 기울기를 계산하므로 **기울기 추정의 분산이 큼** → 학습이 **불안정하게 요동**함.
* **학습률(learning rate)**을 적절히 조정하지 않으면 발산하거나 너무 느리게 수렴함.
* **전역 최적해(global optimum)**까지는 수렴하기 어려움.
* 큰 데이터셋에서는 여전히 **비효율적 반복 계산**이 많음.

3. 그래서 등장한 것이 “Adam (Adaptive Moment Estimation)”

Adam은 이러한 단점을 보완하기 위해 개발된 **적응형(Adaptive) 최적화 알고리즘**입니다.
SGD의 확률성과 모멘텀(momentum), RMSProp의 학습률 보정 방식을 결합했습니다.

**Adam의 핵심 아이디어**

* **1차 모멘트(기울기의 평균)**와
* **2차 모멘트(기울기의 제곱 평균)**을 동시에 추적.
  이를 이용해 **각 파라미터마다 다른 학습률을 자동 조정**합니다.

[
m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
]
[
v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
]
[
\theta_{t+1} = \theta_t - \alpha \frac{\hat{m}_t}{\sqrt{\hat{v}_t} + \epsilon}
]

이 식을 통해 Adam은

* 진동을 줄이고,
* 수렴 속도를 높이며,
* SGD보다 **안정적이고 효율적인 학습 경로**를 확보합니다.

---

https://www.geeksforgeeks.org/digital-logic/implementation-of-xor-gate-from-and-or-and-not-gate/
해당 페이지는 XOR 게이트(배타적 논리합)의 구현 방법을 설명하면서, 
기본 게이트인 AND 게이트, OR 게이트, NOT 게이트 을 이용해
XOR 게이트를 어떻게 구성할 수 있는지 그림과 논리식으로 보여주고 있습니다.
