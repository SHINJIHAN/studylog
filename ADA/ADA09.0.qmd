---
title: "제 9장 회귀분석"
format: html
---

> Reporting Date: October. 15, 2024

한 변수가 다른 변수에 의해 설명 및 예측 과정을 분석하는 회귀분석에 대해 논의하고자 한다.

## 01 기계 학습
Machine Learning

데이터 기반으로 패턴과 규칙을 학습하고, 그 학습된 모델을 활용해
미래 예측, 분류, 의사결정 등을 수행하는 알고리즘 및 방법론을
연구하는 인공지능(AI)의 하위 분야이다.

기계학습은  3 가지의 유형으로 구분된다.


### 1 .  지도 학습
Supervised Learning

입력 변수 X 와 정답에 해당하는 타깃 변수 Y 가 함께 주어졌을 때,
X 로부터 Y 를 예측하는 모델을 학습하는 방법이다.

학습 과정에서는 데이터에 포함된 정답을 활용하여 입력과 출력 간의
규칙을 찾고, 이를 기반으로 새로운 데이터에 대한 예측을 수행할 수 있다.

크게 연속적인 값을 예측하는 회귀 문제와,
특정 범주를 예측하는 분류 문제로 나눌 수 있다.

대표적인 알고리즘으로는 선형 회귀, 로지스틱 회귀, 결정 트리,
K-최근접 이웃(KNN), 서포트 벡터 머신(SVM), 신경망 등이 있다.



### 2 .  비지도 학습
Unsupervised Learning

정답(타깃 변수) 없이 입력 데이터 X 만을 가지고
데이터의 패턴, 구조, 분포를 학습하는 방법이다.

주로 유사한 데이터들을 묶는 군집화,
데이터의 차원을 줄여 본질적인 특성을 추출하는 차원 축소기법이 사용된다.

대표적인 예로는 장바구니 분석(연관 규칙 학습), 다차원 척도법(MDS),
주성분 분석(PCA), 요인 분석(FA) 등이 있다.



### 3 .  강화 학습
Reinforcement Learning

에이전트가 환경(Environment)과 상호작용하며,
각 상태(State)에서 취할 수 있는 행동(Action)을 선택한다.

그 결과로 보상(Reward)을 받으면서, 장기적으로 누적 보상을
최대화할 수 있는 최적의 행동 방식을 학습하는 방법이다.

정답 데이터가 주어지는 것이 아닌 시행착오를 통해
스스로 전략을 개선하는 것이 특징입니다.

이러한 특성 덕분에 강화 학습은 로봇 제어, 게임 인공지능,
자율주행, 추천 시스템 등 순차적 의사결정 문제에 널리 활용된다.

이 중 지도 학습에 속하는 회귀 모델을 중심으로 살펴보고자 한다.


"회귀" 용어의 유래
19세기 후반, 영국의 통계학자 프랜시스 골턴은 유전학 연구에서
부모와 자녀의 키 상관관계를 조사하면서 처음으로 "회귀" 라는 용어를 사용하였다.

그는 부모의 키가 평균보다 크거나 작은 경우, 자녀의 키가
평균값으로 되돌아가는 경향을 발견하였고, 이를 회귀라고 설명하였다.
즉, 자녀들의 키가 부모의 극단적인 키보다 평균에 가까워지는 현상을 의미한 것이다.

이후 골턴의 연구를 바탕으로 칼 피어슨은 회귀 분석을 체계화하고
수학적으로 확장하였으며, 선형 회귀의 공식과 상관계수 개념을 발전시켜
오늘날 회귀는 통계학에서 중요한 분석 도구로 자리잡게 되었다.



## 02 회귀 모델의 정의
회귀 모델은 타겟 변수인 Y 를 예측하기 위해
입력 변수 X 간의 관계를 학습하는 지도 학습의 한 유형이다.

회귀 모델은 목적과 특성에 따라 5 가지 유형으로 구분된다.


### 1 .  종속 변수의 개수에 따른 분류


일변량 회귀
Univariate Regression

하나의 종속 변수 Y 를 예측하기 위해
입력 변수 X 와 Y 간의 관계를 모델링하는 방법이다.



다변량 회귀
Multivariate Regression

여러 개의 종속 변수  Y1, Y2, …, Ym 를 동시에 예측하며,
종속 변수 간의 상관관계와 입력 변수와의 관계를 함께 고려하여
고차원적 관계를 모델링하는 것을 목표로 한다.



### 2 .  두 변수 간의 관계에 따른 분류


선형 회귀
Linear Regression

독립 변수와 종속 변수 사이의 관계가 선형적일 때 사용하는 모델로,
종속 변수를 독립 변수들의 선형 결합으로 표현하며 회귀선을 직선으로 모델링한다.


비선형 회귀
Nonlinear Regression

두 변수 간의 관계가 비선형일 때 사용되며,
다항 회귀나 곡선 형태의 수학적 함수를 통해 관계를 모델링한다.



### 3 .  독립 변수의 개수에 따른 분류


단순 회귀
Simple Regression

하나의 독립 변수 X를 사용하여 종속 변수 Y 를 예측하는 방법이다.


다중 회귀
Multiple Regression

여러 독립 변수  X1, X2, …, Xp ​를 활용해 종속 변수 Y 를 예측하는 방법이다.

현실적인 데이터 분석에서는 종속 변수에 영향을 미치는 요인이
여러 개 존재하는 경우가 많기 떄문에 다중 회귀가 널리 활용된다.



### 4 .  분산과 공분산


분산
Variance

단일 변수의 산포 정도,
즉 값들이 평균으로부터 얼마나 흩어져 있는지를 나타낸다.

회귀 분석에서 종속 변수 Y 의 분산은 데이터가 얼마나 퍼져 있는지를 보여주며,
분산이 작을수록 모델이 더 정밀한 예측을 할 가능성이 높다.


공분산
Covariance

두 변수 간의 선형적 관계를 나타내는 지표로,
두 변수가 함께 어떻게 변하는지를 측정한다.

공분산이 양수이면 두 변수가 같은 방향으로 변하는 경향이 있고,
음수이면 반대 방향으로 변하는 경향이 있다.

다만 공분산 값 자체는 단위의 영향을 받아 크기 비교가 어려워,
이를 표준화한 상관계수(Correlation Coefficient)가 자주 활용된다.


### 5 .  로지스틱 회귀
Logistic Regression

종속 변수가 이진형(Binary)일 때 사용하는 회귀 기법이다.
이진형 변수의 예로는 성공/실패, 생존/사망, Yes/No 등이 있다.

선형 회귀처럼 값을 직접 예측하는 것이 아니라,
특정 사건이 일어날 확률을 예측한다.

예측된 확률은 0 과 1 사이의 값으로 표현되며,
이를 기준으로 특정 클래스로 분류할 수 있다.

이를 위해 선형 회귀 모형을 기반으로 한 결과를
로그 오즈로 변환하고 로지스틱 함수를 적용하여 확률로 해석 가능하게 만든다.




## 03 단순 회귀분석
Simple Linear Regression

하나의 독립 변수 X 와 하나의 종속 변수 Y 간의
선형적 관계를 분석하는 기법이다.

주로 두 변수 사이의 직선적 관계를 파악하고,
이를 바탕으로 종속 변수를 예측하는 데 활용된다.

예를 들어, 예약 건수와 판매량 간의 관계를 분석하거나,
공부 시간과 시험 성적 간의 관계를 분석할 때 적용할 수 있다.


### 1 .  절편
통계적으로 유의하지 않더라도 직선의 위치를 결정하는
수학적 요소이므로 회귀모형에는 일반적으로 포함하며,
실질적인 해석의 초점은 독립변수의 효과를 나타내는 기울기 계수에 맞추어진다.


### 2 .  오차
통계 분석에서 회귀모형은 항상 일정 수준의 오차를 전제로 한다.
만약 오차가 전혀 없다면 모든 데이터가 회귀직선 위에 위치하게 되지만,
실제 데이터에서는 관측값이 직선에서 벗어나기 때문에 오차가 발생한다.

실무에서는 다중선형회귀와 로지스틱 회귀가 가장 많이 활용되며,
단순선형회귀는 주로 기초 개념 학습이나 기본 분석에 사용된다.

단순선형회귀에서 중요한 점은 회귀계수를 추정하는 것으로,
추정된 값은 보통 헷(^) 기호를 붙여 나타낸다.
헷이 없는 기호는 모집단의 실제 모수를 의미한다.



### 3 .  최소제곱법
Ordinary Least Squares, OLS

회귀분석에서 가장 널리 사용되는 회귀계수 추정 방법으로,
잔차(실제값과 예측값의 차이)의 제곱 합을 최소화하여
가장 적합한 회귀 직선을 구하는 기법이다.

이를 통해 회귀 직선의 기울기(β₁)와 절편(β₀)을 추정할 수 있으며,
단순 선형 회귀의 경우 공식은 다음과 같다.


기울기 공식

절편의 공식

### 4 .  회귀계수(기울기) 검정
회귀 분석에서 중요한 요소는 기울기이다.
이는 독립 변수 X 가 종속 변수 Y 에 미치는 평균적 영향을 나타낸다.
이 계수가 통계적으로 유의미한지 검증하기 위해  가설 검정을 수행한다.


가설 설정
Hypothesis Formulation

귀무가설(H₀) :  β = 0  (X 가 Y 에 영향을 주지 않는다)
대립가설(H₁) :  β ≠ 0 (X 가 Y 에 유의한 영향을 준다)

단순 선형 회귀에서는 회귀계수가 2 개(절편, 기울기)이므로 자유도는 n − 2 이다.
여기서 n 은 표본의 크기(데이터 포인트 수)이다.



검정 통계량
Test Statistic

회귀분석에서 검정 통계량(t - 통계량)은
회귀계수가 0 인지 여부를 검정하는 데 사용된다.
즉 독립변수와 종속변수 간의 관계가 유의미한지 검정할 수 있다.

회귀분석에서 계수 추정치에 대한 검정은 주로 t-통계량을 활용하며,
이는 표본의 크기가 충분히 클 경우 정규분포에 근사하지만
원칙적으로는 자유도를 고려한 t - 분포를 따른다.


이러한 검정을 위해 오차항은 평균이 0이고 분산이 일정하며,
서로 독립적으로 정규분포를 따른다는 가정이 필요하다.

이 가정을 바탕으로 회귀계수 β 에 대한 가설검정과 신뢰구간이 설정되며,
연구자는 보통 귀무가설(계수=0)을 기각하고 대립가설(계수≠0)을 채택하기를 기대한다.



기울기의 표준 오차
Standard Error of the Slope

회귀계수(기울기) 추정치의 변동성 또는 신뢰도를 나타내는 값이다.


즉, 동일한 데이터 표본에서 회귀분석을 반복할 경우,
추정된 기울기가 얼마나 변동할 수 있는지를 보여준다.

표준 오차가 작을수록 기울기 추정치가 보다 정확하며,
회귀계수 검정과 신뢰구간 계산에 활용된다.



잔차의 표준편차
Standard Error of the Estimate, σₑ

회귀모형이 데이터를 얼마나 잘 설명하는지를 나타내는 지표로,
단순 선형 회귀에서는 추정할 회귀계수가 2 개(절편과 기울기)이므로 자유도는 n − 2 가 된다.

이 값을 이용하여 회귀계수의 t − 통계량을 계산하고,
이를 기반으로 p − 값을 산출하여 귀무가설 기각 여부를 결정한다.

일반적으로 p − 값이 0.05 보다 작으면 귀무가설을 기각하고,
독립변수가 종속변수에 유의미한 영향을 준다고 판단한다.


단순 회귀분석을 통해 독립 변수와 종속 변수 간의 관계를 파악할 수 있으며,
최소제곱법(OLS)을 사용하여 회귀 직선을 추정한다.

이후 회귀계수의 유의성을 검증하는 가설 검정과 자유도 계산을 통해,
모델이 통계적으로 신뢰할 만한지 판단하고 분석 결과를 해석할 수 있다.


단순 회귀분석 사례
12개의 기업에 대해 1년 광고비와 매출액을 조사하여 얻은 것이다.

```{python}
import pandas as pd

url = "https://raw.githubusercontent.com/SHINJIHAN/advanced-bigdata/main/data/Sales.csv"
Sales = pd.read_csv(url)
Sales.head()
```

```{python}
import matplotlib.pyplot as plt
import seaborn as sns
sns.jointplot(x = 'Adver', y = 'Sales',
             data = Sales, kind = 'reg')

import statsmodels.formula.api as smf
SalesFit = smf.ols(formula = 'Sales ~ Adver',
                   data = Sales).fit()
SalesFit.summary()
```

한편, 결정계수(R^2)는 회귀모형이 종속변수의 변동을 얼마나 설명하는지를 나타내지만,
값이 높다고 해서 항상 좋은 모델을 의미하는 것은 아니며 과적합 여부도 고려해야 한다.

<그림1> 산점도와 회귀직선
데이터를 직관적으로 이해하기 위해 선형 관계를 가정하고 직선 형태의 모델을 사용하는 경우가 많지만, 실제 데이터가 비선형 관계를 보이면 비선형 모델을 적용하기도 한다. 데이터가 선형인지 비선형인지는 산점도를 통해 시각적으로 확인할 수 있으며, 이때 산점도는 독립변수와 종속변수가 모두 연속형일 때 의미가 있다. 한편, 범주형 변수는 산점도로 바로 표현할 수 없지만, 회귀모델에서는 더미 변수로 변환하여 포함시킬 수 있으므로, 범주형 변수 역시 분석에 반영할 수 있다.

```{python}
sns.lmplot(x = 'Adver', y = 'Sales', data = Sales)
sns.regplot(x = 'Adver', y = 'Sales', data = Sales, lowess = True)
```

반응변수에 대한 예측
```{python}
predictions = SalesFit.get_prediction()
predictions.summary_frame(alpha = 0.05).round(3)

SalesNew = pd.DataFrame({'Adver':[20, 30, 40]})
predictions = SalesFit.get_prediction(SalesNew)
predictions.summary_frame(alpha = 0.05).round(3)
```

## 04 잔차 분석
Residual

실제 관측값과 회귀 모형에 의해 추정된 예측값의 차이.

이는 데이터 점과 회귀직선 사이의 수직 거리를 의미한다.
회귀 모델이 데이터를 얼마나 잘 설명하는지를 나타내는 중요한 지표이며,
잔차가 작을수록 모델의 적합도가 높음을 의미한다.

따라서 잔차 분석을 통해 회귀 직선이 데이터를 얼마나 잘 표현하는지,
그리고 모델 가정이 적절히 충족되는지를 평가할 수 있다.

표준화잔차
standardized residuals

표준화는 변수의 값을 평균 0 , 분산 1 로 변환하여
서로 다른 척도를 가진 변수를 비교 가능하게 만드는 과정이다.

이를 통해 특정 변수가 값의 범위가 크다는 이유만으로
회귀분석에서 과도하게 영향을 미치는 문제를 완화할 수 있다.

또한 잔차 분석 단계에서는 표준화 잔차나 학생화 잔차를 사용하여
이상치를 탐지 및 모형의 적합성을 진단하기도 한다.

```{python}
Fitted = SalesFit.predict()
Residual = SalesFit.resid # 순수한 자기 잔차
RStandard = SalesFit.resid_pearson # 표준화잔차
pd.DataFrame({'Fitted':Fitted, 
              'Residual':Residual,
              'RStandard':RStandard})

fig, ax = plt.subplots(figsize = (10, 8))
sns.scatterplot(x = Fitted, y = RStandard)
ax.axhline(y = 0)
```

그러나 표준화는 잔차 간의 독립성을 보장하거나
분산 불균형 문제를 근본적으로 해결하지는 못한다.

독립성 문제는 주로 데이터의 자기상관에서 기인하며,
이분산 문제는 가중회귀나 분산 안정화 변환과 같은 방법을 통해 보완해야 한다.

따라서 표준화는 변수의 스케일을 맞추고 분석의 안정성을 높이는 데 중요한 역할을 하지만,
모든 회귀 진단 문제를 해결하는 방법은 아니라는 점을 유념해야 한다.

## 05 회귀 모델의 기본 가정
회귀분석을 적용하기 위해서는 4 가지 기본 가정이 충족되어야 한다.

### 1 .  선형성
Linearity

독립 변수와 종속 변수 간의 관계가 선형이어야 한다.
이는 산점도 등의 그래프를 통해 확인할 수 있다.

### 2 .  정규성
Normality

오차의 분포가 정규분포를 따라야 한다.
이는 대부분의 데이터가 회귀선이라는 평균값 주변에 집중되어 있어야 함을 의미한다.

```{python}
import numpy as np
sns.distplot(RStandard, bins = 10)

from scipy.stats import probplot
probplot(RStandard, plot = plt)
```


### 3 .  등분산성
Homoscedasticity

독립 변수의 값에 관계없이 오차의 분산이 일정해야 한다.
이 가정들이 만족되지 않으면,모델의 예측 성능이 저하되거나 편향된 결과를 초래할 수 있다.
따라서 회귀 분석을 수행할 때는 현실 문제에서 이러한 가정들이 만족되는지 먼저 확인해야 한다.
가정이 충족되면, 독립 변수와 종속 변수 간의 관계에 따라 적합한 회귀 모델 유형을 선택하여 분석을 진행하면 된다.

### 4 .  독립성
Independence

관측값들 간에는 독립성이 유지되어야 한다.
다중공선성일 경우, 각 독립 변수가 종속 변수에 미치는 영향을 개별적으로 평가하기가 어렵기 때문이다.

```{python}
from statsmodels.stats.stattools import durbin_watson
durbin_watson(RStandard) # 기준: 표준화잔차

import statsmodels.api as sm
fig = plt.figure(figsize = (12, 8))
fig = sm.graphics.plot_regress_exog(SalesFit, 'Adver', fig = fig)
```

---

교제: 파이썬을 활용한 데이터 분석과 응용