---
title: "다변량 분석"
format: html
---

> Reporting Date: November. 18, 2025

[주제] 에 대해 다루고자 한다.


 1 .  제목2
다중회귀 모델로 커퍼가 되었기 때문에 학부에서는 안 배웠다.
군집 분석은 텍스트데이터마이닝 k-민스와 같다고 할 수 있지만 그것은 아니다.

비지도 학습으로서 타겟이 없으며, 

군집의 개수, 내용, 구조 등이 완전하게 알려지지 않는 상태에서 개체들 아이의 유사성 또는
거리에 근거하여 군집을 형성하고 형성된 군집의 특성을 파악해 군집들 간의 관계 분석

유클리드 거리, 맨해튼 거리, 코사인 유사도 등 측도를 달라도 거리로 본다는 점이 공통이다.
지표는 실루엣 계수, 엘보우 기법 등이 있다.

보통은 구형 모양이 가장 안정된 형태

1. 군집이 긴 모양
2. 개체 A,B 구 군집 사이의 고리 역할을 하는 경우

금융(신용카드 고객 행동 패턴 분석)에선 세그멘테이션이 중요하다.
그외에 활용 분야 마케팅(고객 세분화), 헬스케어(환자 그룹 분류), 제조업(불량 패턴 탐지)

계층적 군집 분석, 또는 계보적 군집 분석
[최단, 최장, 형균, 중심, 중위수]연결법 Ward의 방법

과정

1. 먼저 가장 가까운 2개의 개체를 묶어 하나의 군집을 만든다. 딱 하나만
나머지 개체는 각각이 하나의 군집을 이루도록 한다.

2. 그리고 그 상태에서 가까운 것들을 조금씩 묶어 간다.

3. 군집들 간 거리의 측도를 기준으로 각 단계마다 한 쌍씩 병합되어,
최종적으로 개체들을 모두 묶어 하나의 군집을 만드는 단계까지 방봅

각 특징

최단 - 가장 가까운, 덴드로그램에서 긴 병합과정
최장 - 가장 먼 두 데이터, 덴드로그램에서 더 균형 잡힌 클러스터 구조
평균 - 두 데이터의 평균을 만들고 그걸 기반으로 거리 잼
중심 - 클러스터의 중심점을 계산, 중간 정도의 안정적인 군집 형성
중위수 - 거리를 중위값 기준
Ward의 방법 - 가장 많이 쓰임, 분산을 최소화하는 방식

scipy.cluster.hierarshy import l

protein.csv

최단 연결법(싱글)은 군집이 긴 모양에선 쓰지 않는 것이 좋음.
덴드로그램 시각화 함

데이터의 개수 및 빈도까지 고려된다. 단순 거리만 고려되지 않는다.
최단 연결법의 알고리즘, D_0에서 각 거리는 대칭이다. 매트릭스이고, 거리가 가장 짧은 것들을 본다.
예를 들어, 0과 1이 가장 짧으므로 하나의 군집이 된다. d1 d2의 거리는 1이다. 둘을 마지한다. 본래 4X4이였다면.
그러면 행렬이 3X3로 줄어든다. d1 d2는 c1이 된다. 또 다시 2X2로 된다. 이런 식으로 계산된다.

d(p1, p2) = 루트(x2 - x1)^2 + (y2 - y1)^2
계산식 해보기.

최장 연결법(컴플리트), 좀 더 분류를 크게 잘 함.
이것의 알고리즘도 최단과 시작은 비슷, 여기서 계산만 최장으로 한다.
각 알고리즘 기법의 결과 차이가 다르진 않음 그저 그룹잉하는 관점에 차이임.

평균 연결법(어버리지)이전보다 군집이 더 세분화됨.
자신만에 센터를 만든다는 다는 것이 차이

군집 분석은 주관적인 경향이 많음. 현업에서는 경험적을 우선으로 해야 됨.
자신이 배운 통계 솔루션을 너무 들이밀면 안됨. 그 이유는 데이터 결과는 감성적인 패턴이 안나오기 때문.

회사에서는 마스터 세그멘테이션을 지정한다. 고객을 대상으로 1년마다 갱신함.

신용은 가맹점 수수료 밖에 없음, 그러나 금융은 이자가 있음 그래서 금융이 더 많이 벌음.
그래서 각각의 세그멘테이션을 만들어야 되고, 개별로 비교해봐야 된다.

각 요소마다 단위가 다르다면, 표준화하여 진행한다.

중심 연결법도 이전과 마찬가지로 매트릭스를 만든다.
X1과 X2가 있을 때 XX` = D(5*5)으로 계산해서 각 차원의 수가 들어든다.
군집의 분류를 어디부터 짤라야 하는가? 이것이 가장 중요하고 애매하다.
그래서 이를 도와주는 기법이 있다.

그래서 군집 분석은 통계학 분석 치고는 주관성이 약간 들어간 학문이다.

k-평균 군집분석

자주 사용하는 이유는 가장 효과적이고 대표적인 모델이기 때문에 그렇다.

최적분리 군집 방법의 절차

먼저 군집 초기값을 선택한다. 임의로 고르든 규칙적으로 고르든.
그 이후 초기 군집을 형성한다. 초기값들과의 거리를 계산된다.
이때 각 개체가 할당될 때마다 해당 군집의 중심이 그 군집에 속하는 걔체들의 평균 벡터로 다시 계산됨.
센터의 변동이 있음, 이제 별로 변동이 없어질 때까지 군집 중심들의 변화가 일정 수준 이하가 될 때까지 같은 과정을 반복한다.
시간은 많이 걸리나 가장 이상적인 군집분석이다. 각 군집과 구성원들을 묶는 그 방식을 조금씩 바꿔서 진행하는 것이다.

그럼 먼저 군집의 수를 잡는 방식으로 엘보우 기법을 사용한다.
엘보우의 경사도가 의미하는 것은 군집내에 제곱합이다.
굽집내 변이의 합계를 의미한다. 그 값이 작을수록 좋음을 나타내며 이는 동질이다.
WSS가 급격히 감소하다가 완만하게 되는 지점이 적절한 군집의 개수에 대한 후보이다.

단위가 다를 수 있다. 데이터를 표준화시키고 다시 보는 방법도 가능하다.
다만, 유의할 것은 y축의 정보 손실이 발생할 가능성도 있다.

군집 3가지를 보고 싶으나 3차원이야. 그래서 차원을 축약해서 간단하게 
보는 방법이 차원 축소이다. 그리고 각 클러스터가 라벨로 표시된다.
사실상 각 군집을 예측한 것이다. 이 포인트는 이 군집 안에 들어갈 것이다라고.

군집수 성능 지표(군집 결정 기중)

실루엣 계수는 개별 데이터가 할당된 군집 내에 데이터와 얼마나 가깝게 군집화 되어 있는지,
그리고 다른 군집에 있는 데이터와는 얼마나 멀리 있는지를 보는 것.

범위는 -1부터 1까지 마치 상관계수와 같다.
1에 가까울수록 좋은 것이다. 거리는 분산에 의해 결정된다.

붓꽃 데이터는 이미 다 조사를 했는데. 3종이 이미 되어 있다.
그러나 다시 분석을 하는 것은 이 기법으로 정말로 실효성이 있는가 에대한 가설 실험인 것이다.

엘보우 기법과 실루엣 계수간에 차이가 날 수 있다. 이것도 고민되는 이유이다.
갭 통계량, 약간 값을 벙튀기 하는 것. 관측된 군집간 변이와 균일 분포하에서의 군집간 변이의 
기댓값을 비교하는 것으로 그 값이  클때 군집화가 잘 되었을 을 나타낸다.

부스트랩 반복횟수 지정(반복횟수를 크게 하면 시간이 많이 걸리지만 더 좋은 결과를 얻을 수 있다.)

값이 클수록 좋은 것이다. 그러나 만약 그보다 작은 값을 선택했다면?
과적합, 떄문에 그렇다. 이전에 엘보우과 실루엣 계수도 비교해서 결정해야 한다.
기울기도 보고 값의 크기를 더 많이 본다.

즉 보여지는 이론적 배경과 수치보다 현업의 이해도와 융통성이 있어야 된다.
유연하다는 것과 거짓정보를 주는 것은 다른다. 전문가의 의견을 많이 들어서 다 포함해야 한다.
애초에 사람들에게 쓰기 위해서 이론 수학보다 유연하게 만든 학문이기에.

분석사례 - NbClust (군집수를 결정하는 추가적인 통계량 제공)
왜 이 많은 걸 볼까? 그건 각 통계량마다 헛점들이 많기 때문이다.
만약에 2, 3가지로 봐서 명확하게 나오면 괜춘. 근데 애매하면 꼭 여러가지 기법을 총동원해서 
최적의 군집을 찾고 그 성능과 신뢰도까지 보여줄 수 있어야 한다.

가우시안 매트릭스 모델(거리가 아닌 확률로 구한다)

베이지안 군집 분석: 여러개의 혼합된 모델일 경우에 좋다.
다변량 가우시안 모델이다.

베이지안 GMM은 클래스를 사용해서 구현.
군집 수에 대한 불확실성을 반영



검토하는 직관적인 방법
다른 통계적 방식에 비해 상대적으로 굉장히 복잡한 과정을 거친다.

특이값에 민감하다, 이유는 거리 기반이기 때문에
디스턴스 기반이기 떄문에 그렇다.

동일한 자료에 대해 다른 가정에 기초를 둔 여러 가지 군집 방법을 적용했을 때
대부분의 방법에서 제공된 결과가 유사한 결과가 나오는 가?

주어진 자료를 임의적으로 두 부분으로 나누고
각 부분을 독립적으로 군집시키는 방법 이때 군집들이 안정되어 있다면 그 결과는 유사

어떤 군집 분석 방법에 의하여 얻어지는 군집의 안정성을 알아보기 위해
몇 개의 일부 변수를 뺐다 꼈다해보기. 제거하여 군집의 구조에 어떤 영향을 미치게 될 것인가를 고찰하는 방법.







파셜 주성분 분석.(교수님 박사 논문)