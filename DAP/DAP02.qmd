---
title: "Clustering"
format: html
---

> Reporting Date: November. 18, 2025

---

# 01 군집 분석
**비지도 학습(Unsupervised Learning)** 기법의 한 유형이다.<br>

사전에 정의된 타겟 변수(종속 변수)가 존재하지 않는 데이터로부터<br>
**데이터 간 유사성 또는 거리(distance)**를 기반으로 군집(cluster)을 형성하는 방법론이다.<br>

이는 데이터가 어떠한 구조를 내재하고 있을 것으로 가정하되, 
그 구조의 형태—군집의 개수, 모양, 분포—가 **사전에 알려져 있지 않은 상태**에서 적용된다.<br>

군집 분석의 핵심 목적은 다음 두 가지로 요약된다.<br>
1. **군집 형성(Clustering)**: 개체들 간 거리 계산을 통해 자연스러운 그룹을 형성<br>
2. **군집 해석(Cluster Interpretation)**: 형성된 군집의 특성과 군집 간 관계 구조를 분석하여 의미를 도출

## 1. 거리(유사성) 측정 방법론

군집 분석에서 가장 기초적이며 중요한 요소는 
**데이터 간 거리(distance) 또는 유사성(similarity) 계산 방식**이다.<br>
거리 측정 방식에 따라 군집 결과는 크게 달라지므로, 데이터의 특성(연속형/희소벡터/텍스트 등)에 따라 적절한 측도를 선택해야 한다.<br>

측도의 형태가 다르더라도, 군집 분석에서는 **"거리 기반으로 개체 간 유사성을 정의한다는 점"**이 공통적이다.

### 1.1 유클리드 거리
Euclidean Distance<br>
연속형 변수에서 가장 일반적으로 사용되는 거리 척도로, **L2 노름(Norm)**에 해당한다.<br>
두 관측치 $x_i, x_j \in \mathbb{R}^p$ 사이의 유클리드 거리는 다음과 같이 정의된다.

$$
d_{\mathrm{euclid}}(x_i, x_j) = \sqrt{\sum_{k=1}^{p} (x_{ik} - x_{jk})^2}
$$

예를 들어, 2차원 데이터 (p_1=(x_1, y_1)), (p_2=(x_2, y_2))의 경우에는

$$
d(p_1, p_2) = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}
$$

와 같이 간단히 계산할 수 있다.

#### 데이터 표준화

각 변수의 단위가 상이할 경우, 거리 계산이 왜곡될 수 있으므로 표준화가 필요하다.

$$
x' = \frac{x - \mu}{\sigma}
$$

여기서 $\mu$ 는 평균, $\sigma$ 는 표준편차이다.

#### 병합적 계층 군집 분석 절차

1. 모든 개체를 단일 군집(singleton cluster)으로 초기화한다.
   $$
   C_1 = {x_1}, C_2 = {x_2}, \dots, C_n = {x_n}
   $$

2. 현재 존재하는 군집들 간 거리 행렬 $D_0$ 를 계산한다.
   * 행렬은 대칭이며, 각 원소 $d(C_i,C_j)$ 는 군집 $C_i, C_j$ 간 거리이다.

3. 거리 행렬에서 가장 가까운 군집 쌍 $(C_p,C_q)$ 을 선택하여 병합한다.
   * 행렬 크기는 1줄씩 감소하며, 새로운 군집 $C_{new}=C_p \cup C_q$ 가 생성된다.

4. 새로운 군집과 나머지 군집 간 거리를 연결법(Linkage Method)에 따라 재계산한다.

5. 이 과정을 반복하여 최종적으로 모든 개체가 하나의 군집으로 통합될 때까지 진행한다.

### 1.2 맨해튼 거리
Manhattan Distance<br>
L1 노름 기반 거리로, 고차원 데이터에서 유리할 수 있다.

$$
d_{\text{manhattan}}(x_i, x_j) = \sum_{k=1}^{p}\left|x_{ik} - x_{jk}\right|
$$

### 1.3 코사인 유사도
Cosine Similarity<br>
텍스트 마이닝 분야에서 주로 사용되며, 벡터 방향의 유사성을 측정한다.

$$
\text{cos}(x_i, x_j) = \frac{x_i \cdot x_j}{|x_i||x_j|}
$$

코사인 **거리(Cosine Distance)**는 다음과 같이 정의된다.

$$
d_{\text{cosine}} = 1 - \text{cos}(x_i, x_j)
$$

---

## 2. 군집 형성의 구조적 특징

### 2.1 안정적 군집 형태

k-means 기반 군집화 모델은 군집을 수학적으로 **구형(spherical)** 구조로 가정한다.<br>
k-means의 목적함수는 다음을 최소화한다.<br>

$$
\min_{C_1, ..., C_K} \sum_{k=1}^{K} \sum_{x_i \in C_k} |x_i - \mu_k|^2
$$

이는 각 군집 중심(centroid)으로부터의 제곱거리 최소화를 가정하므로,<br>
군집이 **타원형이 아닌 구형에 가까울 때** 성능이 가장 안정적이다.

### 2.2 비정형 군집의 문제 사례

아래의 경우는 k-means 모델에서 성능이 저하되는 대표 사례이다.<br>

1. **군집의 형태가 길고 가는 모양(elongated cluster)인 경우**<br>
   * 구형 중심 거리 기준으로는 정확히 분리되지 않는다.

2. **개체 A, B가 서로 다른 군집 사이에서 ‘다리’ 역할을 하는 중간 위치에 존재하는 경우**<br>
   * 두 군집이 실제로 분리되어 있어도 k=2 가정에서 중심이 왜곡된다.

이와 같은 경우에는 DBSCAN, 계층적 군집(Hierarchical Clustering) 등<br>
**모양 제약이 없는 알고리즘**이 더 유리하다.

## 3. 군집의 품질 평가 지표
군집 해석과 군집 수 결정에서 다양한 지표가 사용된다.

### 3.1 실루엣 계수
Silhouette Coefficient<br>

개체 $i$ 에 대해<br>
* $a(i)$: 같은 군집 내 평균 거리<br>
* $b(i)$: 가장 가까운 다른 군집과의 평균 거리

실루엣 값은

$$
s(i) = \frac{b(i) - a(i)}{\max {a(i), b(i)}}
$$

실루엣 계수는 군집의 응집도(cohesion)와 분리도(separation)를 동시에 평가하는 지표이다.

### 3.2 엘보우 기법
Elbow Method<br>
SSE(Sum of Squared Errors)의 감소율을 관찰하여 **변곡점(elbow)**을 최적 군집 개수로 간주한다.<br>
수식은 k-means 목적함수와 동일하다.

---

## 4. 알고리즘 선택과 실무적 전처리 요건

실무에서는 단순히 거리를 계산하여 k-means를 적용하는 것이 아니라,<br>
다음과 같은 요소가 필수적으로 고려된다.

1. **정규화/표준화(Scaling)**:<br>
   * 변수 간 단위 차이로 인한 거리 왜곡 방지<br>

2. **차원 축소(PCA, t-SNE 등)**:<br>
   * 고차원에서의 거리 희석 현상 해결<br>

3. **거리 측정 방식 선택**:<br>
   * 텍스트 → 코사인<br>
   * 연속형 수치 → 유클리드<br>
   * 이상치 존재 → 맨해튼<br>

4. **알고리즘 선택**<br>
   * 구형 군집 → k-means<br>
   * 임의 형태의 군집 → DBSCAN<br>
   * 계층적 구조 중요 → Hierarchical Clustering<br>

---

## 5. 실무 적용 분야
군집 분석은 다양한 산업 분야에서 핵심 기법으로 활용된다.

### 5.1 금융
Finance<br>
* 신용카드 소비 패턴 분석
* 리스크 기반 고객 세그멘테이션
* 사기 탐지(비정상 패턴 발견)

### 5.2 마케팅
Marketing<br>
* 고객 세분화(Customer Segmentation)
* 구매 행동 기반 타겟 마케팅
* 추천 시스템의 사용자 군집화

### 5.3 헬스케어
Healthcare<br>
* 환자 유형 분류
* 질병 패턴 분석
* 개인 맞춤형 치료 전략 개발

### 5.4 제조업
Manufacturing<br>
* 불량 패턴 탐지
* 공정 조건 기반 군집화
* 유지보수(Preventive Maintenance) 최적화

군집 분석은 특히 "세그멘테이션(Segmentation)" 분야에서 실무적 가치가 매우 높다.

---

# 02 계층적 군집 분석
Hierarchical Clustering<br>
비지도 학습(Unsupervised Learning)의 대표적 방법론으로,<br>
개체 간 유사성 또는 거리 기반으로 군집을 단계적으로 형성 혹은 분해하여 데이터의 구조적 관계를 탐색하는 데 사용된다.<br> 

계보적 군집 분석(Agglomerative Hierarchical Clustering)은<br>
데이터 간 유사성 또는 거리 정보를 기반으로 개체를 단계적으로 병합하여 군집을 형성하며,<br> 
이를 덴드로그램(Dendrogram)으로 시각화함으로써 데이터의 전체 구조를 직관적으로 이해할 수 있다.<br>

이러한 방식은 군집의 수(K)를 사전에 정의할 필요가 없다는 장점을 가지므로, <br>
탐색적 데이터 분석(Exploratory Data Analysis, EDA)에서 데이터 패턴과 잠재적 구조를 파악하는 데 널리 활용된다.<br>

계층적 군집 분석은 크게 **병합적(Agglomerative)** 방식과 **분할적(Divisive)** 방식으로 구분되는데,<br>
실무·연구 대부분에서는 계산적 단순성 및 직관성으로 인해 병합적 방법이 주로 사용된다.<br>

병합적 계층 군집은 각 개체를 단일 군집(singleton cluster)으로 시작하여<br>
단계적으로 가장 가까운 군집을 반복적으로 병합함으로써 최종적으로 전체 개체가 하나의 군집으로 통합될 때까지 진행된다.<br>
이 과정은 **덴드로그램(Dendrogram)**으로 시각화할 수 있으며, 시각화 과정에서 데이터 개수와 빈도가 함께 고려되기도 한다.<br>

## 1. 병합적 계층 군집 분석의 절차

### 1.1 초기 단계
분석 대상 개체가 ( n )개라고 할 때, 초기에는 모든 개체가 단독 군집으로 간주된다.

$$
C_1 = {x_1}, C_2 = {x_2}, \ldots, C_n = {x_n}
$$

이후 각 군집 간 거리(유사성)가 거리 행렬(distance matrix)로 표현되며,<br> 
이 행렬은 군집 병합 과정에서 매 단계 재계산된다.

### 1.2 단계별 병합(algo) 과정

각 단계에서는 다음 두 규칙이 반복적으로 적용된다.<br> 

1. **현재 존재하는 모든 군집 쌍 중 가장 가까운 군집을 찾는다.**
   $$
   (C_p, C_q)=\arg\min_{C_i, C_j} d(C_i,C_j)
   $$

2. **해당 두 군집을 하나의 군집으로 병합한다.**
   $$
   C_{new}=C_p \cup C_q
   $$

3. **병합 후, 새로운 군집과 다른 군집 간의 거리를 '연결법(Linkage Method)'에 따라 재계산한다.**

이 과정이 반복되어<br> 
$$
n \rightarrow n-1 \rightarrow n-2 \rightarrow \cdots \rightarrow 1
$$
최종적으로 하나의 군집으로 통합된다.<br> 

이러한 병합 과정을 시각적으로 나타낸 것이 **덴드로그램(Dendrogram)**이며,<br>
수평선의 높이(height)는 해당 병합 단계에서의 군집 간 거리 혹은 이질성(Heterogeneity)을 나타낸다.

## 2. 연결법
Linkage Methods<br>
군집 간 거리 계산 방식은 계층적 군집 분석의 결과에 직접적으로 영향을 미치는 핵심 요소이다.<br> 
아래는 대표적 연결법들의 **정의, 수학적 공식, 특징, 구조적 영향**을 상세히 정리한 것이다.

### 2.1 최단 연결법
Single Linkage<br>
두 군집 간 최소 거리(minimum pairwise distance)를 사용한다.
$$
d_{\text{single}}(C_i,C_j)=\min_{x \in C_i,, y \in C_j} d(x,y)
$$

**특징:**
* **Chain Effect(사슬 현상)** 발생 가능성이 높음
  (길게 늘어지는 패턴이 나타나며, 여러 개체가 얇은 줄처럼 연결되어 있는 구조)
* 개별 데이터들이 사슬처럼 연결되어 길게 늘어난 형태의 군집이 형성될 수 있음
* 군집 모양 취약: 좁고 길게 늘어진(Elongated) 군집에서는 적합하지 않음
* 잡음과 이상치 민감: 외곽 점(outlier)에 의해 군집 구조가 쉽게 왜곡됨

**실무적 주의:**
* 단순 거리만 고려하므로, 실제 데이터의 밀도나 분포를 충분히 반영하지 못할 수 있음
* 군집 결과가 직관적이지 않거나 왜곡될 수 있으므로, 데이터 특성을 고려하여 다른 연결법과 병행 평가 필요

### 2.2 최장 연결법
Complete Linkage<br>
두 군집 간 최대 거리(maximum pairwise distance)를 사용한다.
$$
d_{\text{complete}}(C_i,C_j)=\max_{x \in C_i,, y \in C_j} d(x,y)
$$

**특징:**
  * 군집 내부가 조밀(compact)하게 유지됨
    (각 군집 내 데이터 간 최대 거리를 고려하기 때문)
  * 이상치와 잡음의 영향을 Single linkage 대비 상대적으로 덜 받음
    (**균형 잡힌 군집 구조(Balanced Cluster Structure)** 생성)
  * 덴드로그램 상에서 병합 높이가 일정하게 유지되어 구조가 시각적으로 균형 있게 나타남

**실무적 고려:** 
* 분류 경계가 명확해야 하는 경우 유용
* 군집 간 거리 기준이 엄격하여, 너무 작은 군집이 과도하게 분리되는 경우 주의 필요

### 2.3 평균 연결법
Average Linkage / UPGMA<br>
군집 간 모든 개체 쌍의 거리 평균을 사용한다.

$$
d_{\text{average}}(C_i,C_j)
= \frac{1}{|C_i|\cdot |C_j|}
\sum_{x\in C_i}\sum_{y\in C_j} d(x,y)
$$

**특징:**
* 군집 간 전체적 거리 구조를 반영
  (단일 연결법의 사슬 현상 + 최장 연결법의 지나친 조밀화를 완화)
* 극단적 이상치에 대한 민감도가 단일/최장 연결법보다 낮음
* 평균 기반 병합으로 군집 내 구조를 보다 세밀하게 반영
* 모든 데이터 쌍의 평균 거리 기반으로 병합이 이루어짐
* 병합 높이가 극단적으로 치우치지 않고, 일정한 간격을 유지하며 균형 있는 시각적 구조를 보여줌

### 2.4 중심 연결법 
Centroid Linkage<br>
각 군집의 중심(centroid)을 계산한 뒤 중심 간 거리로 측정.

$$
\text{군집} C_i \text{의 중심}: \mu_i=\frac{1}{|C_i|}\sum_{x\in C_i} x
$$

$$
\text{군집 간 거리}: d_{\text{centroid}}(C_i,C_j)=|\mu_i-\mu_j|
$$

**특징:**
* 중심 계산과 거리 계산이 행렬 연산으로 처리 가능하여 구현 용이
* 군집이 선형적으로 분리되거나 중심 기반 구조가 뚜렷한 경우 성능이 우수
* 중심만 계산하면 되므로, 반복 연산이 많은 대규모 데이터에서 계산이 비교적 효율적
* 중심 이동으로 인해 Single/Complete/Average보다 덴드로그램의 구조가 덜 안정적일 수 있음
* 역병합(Reversal) 발생 가능성 높음
  (군집 병합 후 새로운 중심이 기존 거리 구조를 뒤흔들어
  덴드로그램 높이가 역전되는 비단조성(non-monotonicity) 문제가 발생하기 쉬움)
* 컷(cut) 기준의 주관성
  (덴드로그램의 높이가 단조 증가하지 않아, 
  군집 수 결정 시 절단 시점 판단이 더 주관적일 수 있음)

### 2.5 중위수 연결법 
Median Linkage<br>
두 군집 중심의 중위값(median)을 기반으로 정의하며, Centroid linkage와 유사하나 중심 계산 방법이 다르다.

$$
\text{병합 후 새로운 중심}: \mu_{new}=\frac{1}{2}(\mu_i+\mu_j)
$$

**특징:**
* 중위수 사용으로 극단값의 영향을 평균보다 적게 받음
  (단, 전체 군집 구조 안정성 문제를 해결할 수준의 강인성(robustness)은 아님)
* 중위수 기반이므로 계산 과정은 상대적으로 단순하고 구현 난이도도 낮음

* 역병합(Reversal) 발생 가능성 높음
  (Centroid와 마찬가지로 병합 후 새 중위수 위치가 기존 거리 구조를 비단조적으로 변화시켜
  **덴드로그램 높이 역전(Non-monotonicity)**이 발생할 수 있음)

* 여러 연구에서 Centroid와 유사하게 군집 구조가 불안정하다는 보고가 존재
  (특히 군집 분리 기준이 덴드로그램에서 명확하지 않은 경우가 잦음)
* 데이터가 비정상적 분포(heavy-tailed)거나 극단값이 많은 경우 평균 기반보다 중위수 기반이 유리할 수 있음
  (그러나 덴드로그램 해석의 비단조성 문제와 불안정성 때문에 
  Single, Complete, Average, Ward 방식보다 권장 빈도가 현저히 낮음)
* 따라서 실무·통계 패키지에서 기본 옵션으로 잘 사용되지 않으며, 실증 연구에서도 활용 빈도가 다른 연결법 대비 매우 낮음

### 2.6 Ward의 방법 
Ward’s Minimum Variance Method<br>
군집 병합 시 전체 군집 내 오류제곱합(SSE, Within-Cluster Sum of Squares)의 증가를 최소화하는 방법.

$$
\text{군집} C \text{의} SSE: \quad SSE(C)=\sum_{x\in C}|x-\mu_C|^2
$$

Ward 방식은 다음을 최소화한다:<br>
$$
\Delta = SSE(C_i \cup C_j) - (SSE(C_i)+SSE(C_j))
$$

**특징:**
* **가장 널리 사용되는 연결법**
* 군집이 구형(spherical) 형태로 형성됨
  (분산 최소화 원리로 인해 밀집되고 균형 잡힌 구형 구조를 만들기 쉬움)
* 단일·최장 연결법보다 이상치 영향이 적고 안정적인 군집 구조를 형성
  (병합 높이(height)가 비교적 균일하게 증가 → 매우 안정적이고 해석이 쉬운 덴드로그램 구조를 제공
  군집 간 병합 폭이 일정해 분기(branch)가 균형적으로 나타남)
* 군집 내 제곱합 기반이라 군집 간 차이가 직관적으로 해석 가능
* k-means와 유사한 알고리즘적 성향 (분산 최소화)
  (둘 다 군집 내 변동을 최소화하는 방향으로 동작 → 결과 군집 형태가 유사해지는 경향.)

**실무적 고려:** 
* 데이터가 연속형이며, 군집이 구형에 가까운 구조일 때 가장 적합
* 고차원 데이터에서도 안정적이지만, 분산 계산 특성상 변수 스케일링(표준화)이 필수
* 비구형 구조(long, chain-like cluster)를 가진 데이터에서는 과도하게 조밀한 군집이 생성될 수 있음

## 3. 실무적 고려 사항
계층적 군집 분석은 다음과 같은 실무적 특성이 존재한다.

### 3.1 연산 복잡도
* 거리 행렬 계산: $O(n^2)$
* 전체 병합 과정: $O(n^3)$ (일반적 구현 기준)

→ 데이터가 많아지면 실무에서 **수천 개 이상은 사실상 불가능**<br> 
→ 샘플링, 차원 축소 병행 필요

### 3.2 데이터 전처리 필요성

* 거리 기반이므로 **표준화(Standardization)** 필수
  $$
  x'=\frac{x-\mu}{\sigma}
  $$

* 이상치(outlier)에 매우 민감 → 사전 처리 필요
* 고차원 데이터에서는 차원의 저주로 성능 저하 → PCA 필요

### 3.3 군집 수 결정
* 덴드로그램의 컷 높이(cut height)
* 비일관성 계수(inconsistency coefficient)
* 코페네틱 상관계수(cophenetic correlation coefficient) 등 고려

### 3.4 주관성 존재
* 덴드로그램 컷(cut height) 결정, 연결법 선택,
* 최종 군집 수 결정은 분석자의 경험과 목적에 크게 의존

### 3.5 실무 활용
* 단위가 다른 변수는 반드시 표준화 필요
* 통계적 솔루션만 적용하면 데이터의 감성적 패턴 반영 부족
* 마케팅/금융에서 고객 세그멘테이션, 1년 단위 갱신 등 경험적 기준 적용

### 3.6 알고리즘 관점
* 최단, 최장, 평균, 중심 연결법 결과는 병합 순서나 군집 모양에서 차이가 발생하지만, 최종 그룹화 자체는 모두 유사
* 관점 차이일 뿐, 전체적인 군집 구조 탐색에는 유용함

---

protein.csv

---

k-평균 군집분석

자주 사용하는 이유는 가장 효과적이고 대표적인 모델이기 때문에 그렇다.

최적분리 군집 방법의 절차

먼저 군집 초기값을 선택한다. 임의로 고르든 규칙적으로 고르든.
그 이후 초기 군집을 형성한다. 초기값들과의 거리를 계산된다.
이때 각 개체가 할당될 때마다 해당 군집의 중심이 그 군집에 속하는 걔체들의 평균 벡터로 다시 계산됨.
센터의 변동이 있음, 이제 별로 변동이 없어질 때까지 군집 중심들의 변화가 일정 수준 이하가 될 때까지 같은 과정을 반복한다.
시간은 많이 걸리나 가장 이상적인 군집분석이다. 각 군집과 구성원들을 묶는 그 방식을 조금씩 바꿔서 진행하는 것이다.

그럼 먼저 군집의 수를 잡는 방식으로 엘보우 기법을 사용한다.
엘보우의 경사도가 의미하는 것은 군집내에 제곱합이다.
굽집내 변이의 합계를 의미한다. 그 값이 작을수록 좋음을 나타내며 이는 동질이다.
WSS가 급격히 감소하다가 완만하게 되는 지점이 적절한 군집의 개수에 대한 후보이다.

단위가 다를 수 있다. 데이터를 표준화시키고 다시 보는 방법도 가능하다.
다만, 유의할 것은 y축의 정보 손실이 발생할 가능성도 있다.

군집 3가지를 보고 싶으나 3차원이야. 그래서 차원을 축약해서 간단하게 
보는 방법이 차원 축소이다. 그리고 각 클러스터가 라벨로 표시된다.
사실상 각 군집을 예측한 것이다. 이 포인트는 이 군집 안에 들어갈 것이다라고.

군집수 성능 지표(군집 결정 기중)

실루엣 계수는 개별 데이터가 할당된 군집 내에 데이터와 얼마나 가깝게 군집화 되어 있는지,
그리고 다른 군집에 있는 데이터와는 얼마나 멀리 있는지를 보는 것.

범위는 -1부터 1까지 마치 상관계수와 같다.
1에 가까울수록 좋은 것이다. 거리는 분산에 의해 결정된다.

붓꽃 데이터는 이미 다 조사를 했는데. 3종이 이미 되어 있다.
그러나 다시 분석을 하는 것은 이 기법으로 정말로 실효성이 있는가 에대한 가설 실험인 것이다.

엘보우 기법과 실루엣 계수간에 차이가 날 수 있다. 이것도 고민되는 이유이다.
갭 통계량, 약간 값을 벙튀기 하는 것. 관측된 군집간 변이와 균일 분포하에서의 군집간 변이의 
기댓값을 비교하는 것으로 그 값이  클때 군집화가 잘 되었을 을 나타낸다.

부스트랩 반복횟수 지정(반복횟수를 크게 하면 시간이 많이 걸리지만 더 좋은 결과를 얻을 수 있다.)

값이 클수록 좋은 것이다. 그러나 만약 그보다 작은 값을 선택했다면?
과적합, 떄문에 그렇다. 이전에 엘보우과 실루엣 계수도 비교해서 결정해야 한다.
기울기도 보고 값의 크기를 더 많이 본다.

즉 보여지는 이론적 배경과 수치보다 현업의 이해도와 융통성이 있어야 된다.
유연하다는 것과 거짓정보를 주는 것은 다른다. 전문가의 의견을 많이 들어서 다 포함해야 한다.
애초에 사람들에게 쓰기 위해서 이론 수학보다 유연하게 만든 학문이기에.

분석사례 - NbClust (군집수를 결정하는 추가적인 통계량 제공)
왜 이 많은 걸 볼까? 그건 각 통계량마다 헛점들이 많기 때문이다.
만약에 2, 3가지로 봐서 명확하게 나오면 괜춘. 근데 애매하면 꼭 여러가지 기법을 총동원해서 
최적의 군집을 찾고 그 성능과 신뢰도까지 보여줄 수 있어야 한다.

가우시안 매트릭스 모델(거리가 아닌 확률로 구한다)

베이지안 군집 분석: 여러개의 혼합된 모델일 경우에 좋다.
다변량 가우시안 모델이다.

베이지안 GMM은 클래스를 사용해서 구현.
군집 수에 대한 불확실성을 반영



검토하는 직관적인 방법
다른 통계적 방식에 비해 상대적으로 굉장히 복잡한 과정을 거친다.

특이값에 민감하다, 이유는 거리 기반이기 때문에
디스턴스 기반이기 떄문에 그렇다.

동일한 자료에 대해 다른 가정에 기초를 둔 여러 가지 군집 방법을 적용했을 때
대부분의 방법에서 제공된 결과가 유사한 결과가 나오는 가?

주어진 자료를 임의적으로 두 부분으로 나누고
각 부분을 독립적으로 군집시키는 방법 이때 군집들이 안정되어 있다면 그 결과는 유사

어떤 군집 분석 방법에 의하여 얻어지는 군집의 안정성을 알아보기 위해
몇 개의 일부 변수를 뺐다 꼈다해보기. 제거하여 군집의 구조에 어떤 영향을 미치게 될 것인가를 고찰하는 방법.

파셜 주성분 분석.(교수님 박사 논문)