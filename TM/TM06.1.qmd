---
title: "6장: 감성 분석"
format: html
---

> Reporting Date: May. 20, 2025

감성분석에 대해 다루고자 한다.

01 감성 사전 다운


 1 .  KNU

GitHub - park1200656/KnuSentiLex: KNU(케이앤유) 한국어 감성사전

KNU(케이앤유) 한국어 감성사전. Contribute to park1200656/KnuSentiLex development by creating an account on GitHub.

github.com
import json

file_path = r'C:\Users\jkl12\Downloads\KnuSentiLex-master\KnuSentiLex-master\data\SentiWord_info.json'

with open(file_path, 'r', encoding='utf-8') as f:
    json_data = json.load(f)

# 단어 리스트 생성
word_list = []
for item in json_data:  # 리스트 반복
    word_txt = item['word']
    word_list.append(word_txt)

# 결과 출력 (앞 10개만 보기)
print(word_list[:10])


 2 . KoreanSentimentAnalyzer

GitHub - mrlee23/KoreanSentimentAnalyzer: 한국어 감성 분석기

한국어 감성 분석기. Contribute to mrlee23/KoreanSentimentAnalyzer development by creating an account on GitHub.

github.com
import pandas as pd

# 파일 경로
file_path = r'C:\Users\jkl12\Downloads\KoreanSentimentAnalyzer-master\KoreanSentimentAnalyzer-master\dic\polarity.csv'

# CSV 파일 읽기
senti_df = pd.read_csv(file_path, encoding='utf-8')  # 또는 encoding='cp949'
senti_df.head()




import pickle

# 파일 저장 위치
file_path = r'C:\Users\jkl12\텍스트마이닝\\'

# doc_topic과 comment_topic이 포함된 파일
f = open(file_path + 'topic_doc.pkl', "rb")  # 데이터 불러오기
data = pickle.load(f)
f.close()

data  # 문서 전체의 명사 리스트 확보


KNU 감성사전을 이용해서 텍스트 데이터에 감정 점수를 부여하는 Python 스크립트입니다.
각 텍스트가 긍정적인지, 부정적인지, 중립적인지를 파악하기 위해 사용됩니다.

import json
import pandas as pd
from tqdm import tqdm

# 감정분석 JSON 데이터 (KNU 감성사전) 불러오기
file_path = r'C:\Users\jkl12\Downloads\KnuSentiLex-master\KnuSentiLex-master\data'

with open(file_path + r'\SentiWord_info.json', encoding='UTF-8') as json_file:
    sentiword = json.load(json_file)

# 감성 단어 리스트 및 점수 초기화
s_word = []
values = []
score = []

# 평균 계산 함수
def average(lst):
    return sum(lst) / len(lst)


텍스트에서 감성 단어 찾고 점수 계산

# 감성 점수 계산
for word in tqdm(data['doc']):
    temp_s_word = [] # 본문에서 가져옴
    temp_value = []

    for s in sentiword:
        if s['word'] in word:
            temp_s_word.append(s['word'])
            temp_value.append(int(s['polarity']))

    s_word.append(temp_s_word)
    values.append(temp_value)

    if len(temp_value) > 0:
        score.append(average(temp_value))
    else:
        score.append(0)

# 결과 삽입
data = data.assign(sentiword=s_word, values=values, score=score)
data


가상 공간 안에서만 있는 것, 이를 저장 함.

import pickle
import pandas as pd

# 저장
file_path = r'C:\Users\jkl12\텍스트마이닝\\'
with open(file_path + "total_docs_KNU.pkl", "wb") as f:
    pickle.dump(data, f)

# 불러오기
with open(file_path + "total_docs_KNU.pkl", "rb") as f:
    ff = pickle.load(f)




# 데이터프레임 복원
total_docs = pd.DataFrame()
total_docs['doc'] = ff['doc']
total_docs['doc_token_noun'] = ff['doc_token_noun']
total_docs['doc_topic'] = ff['doc_topic']
total_docs['comment_topic'] = ff['comment_topic']
total_docs['sentiword'] = ff['sentiword']
total_docs['values'] = ff['values']
total_docs['score'] = ff['score']

total_docs

doc_token_noun의 모든 단어가 감성 단어가 아니다.
그들 중 감성 단어를 sentiword로 불러온 것.



from wordcloud import WordCloud
import matplotlib.pyplot as plt

# 폰트 경로 (Windows용 예시 - 나눔고딕)
font_path = r"C:\Users\jkl12\Downloads\NanumGothicBold.otf"

# 토픽 개수만큼 반복
num_topics = total_docs['doc_topic'].nunique()

for topic_num in range(num_topics):
    # 해당 토픽의 문서 필터링
    topic_docs = total_docs[total_docs['doc_topic'] == topic_num]
    
    # 토큰 리스트를 하나로 합치기 (flatten)
    all_tokens = sum(topic_docs['doc_token_noun'], [])
    
    # 문자열로 변환 (공백으로 연결)
    text = ' '.join(all_tokens)
    
    # 워드클라우드 생성
    wordcloud = WordCloud(font_path=font_path, background_color='white', width=800, height=400).generate(text)
    
    # 시각화
    plt.figure(figsize=(10, 8))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title(f"Topic {topic_num} Word Cloud", fontsize=16)




이 코드는 감성 점수(score)를 기준으로 각 토픽(doc_topic)에 대해 감정 분포를 분류하고 있습니다.

if score > 0.3:          # 긍정
elif -0.3 <= score <= 0.3: # 중립
else:                    # 부정
여기서 "0.3"과 "-0.3"이라는 기준은 **사용자가 임의로 정한 값 (threshold)**입니다.
→ 즉, 이 기준이 정해진 절대값이 아니라,
→ 분석 목적에 따라 조정해야 하는 값이에요.



🧠 사용자가 결정해야 할 것들
score의 값 범위가 어떻게 구성되어 있는가?
감성 점수가 -2 ~ 2인지, -1 ~ 1인지, -5 ~ 5인지 먼저 확인해야 합니다.
0.3이 의미 있는 경계값인가?
감성 점수의 분포가 대부분 -0.1 ~ 0.1이라면, 0.3은 너무 높은 기준일 수 있습니다.
반대로 감성 점수 범위가 크다면, 0.3은 너무 낮은 기준일 수 있죠.
목표에 따라 기준이 달라질 수 있음
예를 들어:
마케팅 분석이라면 조금만 긍정적이어도 긍정으로 간주
감정 민감도 분석이라면 더 엄격한 기준 적용 필요



코드에서 senti_0 = [0, 0, 0, 0, 0, 0] 의미
이 리스트는 **특정 토픽(topic 0, topic 1 등)**에 대한 감성 점수 분포를 저장하려고 만든 것입니다.
즉, 각 인덱스가 감정의 강도나 구간을 나타냅니다.

0	매우 긍정
1	긍정
2	중립
3	부정
4	매우 부정
5	기타 / 미정 (혹은 사용자 정의)
그런데 본문 코드에서는 실제로는 0, 2, 4만 사용되고 있죠?
이건 중간 단계일 가능성도 있고, 나중에 더 구체적인 등급으로 확장하기 위해 미리 6칸 확보해둔 것일 수도 있어요.

🧠 핵심 포인트
senti_0, senti_1은 토픽별 감정 분포를 담기 위한 그릇입니다.
토픽이 더 늘어나면?
→ senti_2, senti_3, ... 식으로 계속 만들어야겠죠.
또는 다음처럼 딕셔너리 구조로 더 깔끔하게 관리할 수도 있어요:
senti_dict = {i: [0, 0, 0, 0, 0, 0] for i in total_docs['doc_topic'].unique()}
✅ 요약
항목 설명

senti_0, senti_1	토픽별 감정 분포 저장용 리스트
길이 6	감정 강도 6단계로 분류하려는 구조 (0~5)
사용자 정의 가능	목적에 따라 개수, 의미를 직접 설정
필요하시면 이 구조를 자동화해서 n개의 토픽에 대해 감정 분포를 계산하는 코드도 만들어드릴 수 있어요. 원하시나요?



긍정 / 중립 / 부정의 빈도와 비율을 토픽별로 확인하려는 거군요.

각 토픽(topic)마다
긍정: score > 0.3
중립: -0.3 ≤ score ≤ 0.3
부정: score < -0.3
해당 범주의 빈도수와 **비율(%)**을 구하기

감정 빈도
doc_topic negative neutral positive

0	12	56	32
1	8	30	62

감정 비율 (%)
doc_topic negative neutral positive

0	12.0	56.0	32.0
1	8.0	30.0	62.0


# 토픽별 감성 점수 분류 리스트 초기화 (긍정, 중립, 부정)
senti_0 = [0, 0, 0, 0, 0, 0]
senti_1 = [0, 0, 0, 0, 0, 0]
senti_2 = [0, 0, 0, 0, 0, 0]
senti_3 = [0, 0, 0, 0, 0, 0]

for i in range(len(total_docs)):
    topic = total_docs['doc_topic'].iloc[i]
    score = total_docs['score'].iloc[i]

    if topic == 0:
        if score > 0.3:
            senti_0[0] += 1
        elif -0.3 <= score <= 0.3:
            senti_0[2] += 1
        else:
            senti_0[4] += 1

    elif topic == 1:
        if score > 0.3:
            senti_1[0] += 1
        elif -0.3 <= score <= 0.3:
            senti_1[2] += 1
        else:
            senti_1[4] += 1

for i in range(len(total_docs)):
    topic = total_docs['comment_topic'].iloc[i]
    score = total_docs['score'].iloc[i]

    if topic == 0:
        if score > 0.3:
            senti_2[0] += 1
        elif -0.3 <= score <= 0.3:
            senti_2[2] += 1
        else:
            senti_2[4] += 1

    elif topic == 1:
        if score > 0.3:
            senti_3[0] += 1
        elif -0.3 <= score <= 0.3:
            senti_3[2] += 1
        else:
            senti_3[4] += 1




지금 작성하신 코드는 토픽별 감정 분포 리스트에서 비율(%)을 1칸씩 띄워서 저장하는 방식입니다.

📦 구조 요약
senti_0 = [긍정_빈도, 긍정_비율, 중립_빈도, 중립_비율, 부정_빈도, 부정_비율]

인덱스 0, 2, 4: 빈도수 (count)
인덱스 1, 3, 5: 비율 (ratio, 혹은 percentage)
🔁 반복문 설명
for i in range(1, 7, 2):  # i는 1, 3, 5
i-1 → 현재 비율을 계산할 빈도 인덱스
i → 비율을 저장할 인덱스
분모는 전체 감정의 합: 긍정 + 중립 + 부정
즉, 예를 들어:

senti_0[1] = senti_0[0] / (senti_0[0] + senti_0[2] + senti_0[4])
이건 긍정 비율,
그다음 senti_0[3]은 중립 비율,
senti_0[5]는 부정 비율이 되는 식입니다.



# 감성 클래스별 비율 계산 (분모가 0일 경우 예외 처리 추가)
for i in range(1, 7, 2):
    if (senti_0[0] + senti_0[2] + senti_0[4]) != 0:
        senti_0[i] = senti_0[i-1] / (senti_0[0] + senti_0[2] + senti_0[4])
    else:
        senti_0[i] = 0  # 분모가 0이면 비율을 0으로 설정

    if (senti_1[0] + senti_1[2] + senti_1[4]) != 0:
        senti_1[i] = senti_1[i-1] / (senti_1[0] + senti_1[2] + senti_1[4])
    else:
        senti_1[i] = 0  # 분모가 0이면 비율을 0으로 설정

    if (senti_2[0] + senti_2[2] + senti_2[4]) != 0:
        senti_2[i] = senti_2[i-1] / (senti_2[0] + senti_2[2] + senti_2[4])
    else:
        senti_2[i] = 0  # 분모가 0이면 비율을 0으로 설정

    if (senti_3[0] + senti_3[2] + senti_3[4]) != 0:
        senti_3[i] = senti_3[i-1] / (senti_3[0] + senti_3[2] + senti_3[4])
    else:
        senti_3[i] = 0  # 분모가 0이면 비율을 0으로 설정



# 토픽별 감성 비율 데이터프레임 생성
graph = pd.DataFrame(
    [senti_0, senti_1, senti_2, senti_3],
    index=['topic1', 'topic2', 'topic3', 'topic4'],
    columns=[['긍정', '긍정', '중립', '중립', '부정', '부정'],
             ['빈도', '비율', '빈도', '비율', '빈도', '비율']]
)

graph


🔍 왜 워드클라우드와 감정 점수(혹은 분류) 결과가 다를 수 있는가?
1. 워드클라우드는 감성 단어 필터 없이 모든 단어 사용
일반적으로 워드클라우드는 특정 토픽에서 자주 등장한 단어의 빈도만을 시각화합니다.
이 과정에서 감성 사전에 없는 **중립 단어, 불용어(의미 없는 단어)**들도 포함될 수 있습니다.
따라서 시각적으로 중요한 단어처럼 보여도 감성 점수 계산에서는 무시될 수 있습니다.
2. KNU 감성사전 기반 감정 점수는 '등록된 감성 단어'만 사용
예: 좋다, 싫다, 기쁘다, 화나다 등만 감성 점수로 환산됨.
감성 사전에 없는 단어는 아무리 많이 나와도 score에 기여하지 않음.
3. 토픽의 특성과 감성 단어 간 연관성 결여
예를 들어, 주제는 부정적인 사건이라도 직접적으로 부정 단어(예: "나쁘다", "불편하다")가 없을 수 있음.
이 경우 토픽 자체는 부정적으로 보이지만, 감성 점수는 중립 혹은 긍정이 나올 수 있습니다.
4. 토픽 내 감성 단어 비율이 낮은 경우
감성 점수를 계산할 때 사용하는 감성 단어 수가 전체 단어에 비해 매우 적다면, score의 분포도 좁거나 왜곡될 수 있습니다.
이로 인해 score는 0 근처로 몰리거나, 예외적으로 높은 감성 단어 하나에 과도하게 영향받을 수 있습니다.
✅ 요약
요소특징감성 점수에 반영됨?
워드클라우드 주요 단어	빈도가 높은 모든 단어	❌ 감성 단어만 반영됨
감정 점수(score)	감성사전에 있는 단어 기반	✅ 해당 단어만 반영됨
감정 판단 정확도	단어 수, 감성 단어 존재 여부에 민감	상황에 따라 다름

💡 개선 팁
워드클라우드 만들 때 감성 단어만 필터링해서 시각화할 수도 있습니다.
python
복사편집
sentiment_words = [s['word'] for s in sentiword] topic_words = [word for word in topic_docs if word in sentiment_words]
감성 점수 외에도 TF-IDF 기반 상위 감성 단어 추출도 좋은 방법입니다.
감성 점수 분포와 함께 워드클라우드 결과를 비교 분석하면 더 풍부한 인사이트를 얻을 수 있습니다.


01 감성 사전 다운


 1 .  NRC

NRC Emotion Lexicon

Impact Some notable ways in which the NRC Emotion Lexicon has made impact include: First of its kind: It was the first word-emotion association lexicon, with entries for eight basic emotions as well as positive and negative sentiment. It still remains the

saifmohammad.com






이 코드는 **NRC 감성사전 (Korean NRC Emotion Lexicon)**을 기반으로 각 문서의 감정값을 계산하는 과정입니다. 간단히 말하면, 문서에 등장하는 감성 단어를 찾아서 해당 감정 점수를 누적하는 구조입니다.

아래에 코드의 의미를 단계별로 설명드리겠습니다:

🔢 코드 설명
for i in range(1, len(nrc)):  # NRC 감성사전의 각 단어에 대해 반복
nrc: NRC 감성사전을 담은 DataFrame입니다.
nrc['Korean Word']: 감성사전에 있는 한국어 단어.
range(1, len(nrc)): 아마 첫 번째 행(헤더 또는 불필요한 데이터)을 생략하고자 1부터 시작한 것 같습니다.
if nrc['Korean Word'][i] in word:
현재 문서(word)에 감성사전의 단어가 포함되어 있는지 확인.
if len(nrc['Korean Word'][i]) > 1:
글자 수가 1자인 경우(ex. "다", "게")는 보통 의미가 불분명하거나 너무 일반적이라 제외.
따라서 두 글자 이상인 감성 단어만 사용.
temp_s_word.append(nrc['Korean Word'][i])
해당 감성 단어를 temp_s_word 리스트에 저장 (이 문서에서 발견된 감성 단어 목록).
b = list(map(int, nrc.iloc[i, 1:11].tolist()))
nrc.iloc[i, 1:11]: 해당 단어에 대한 감정 점수들 (예: 긍정, 부정, 분노, 기쁨 등 10가지 감정).
map(int, ...): 감정 점수들이 문자열로 되어 있다면 정수로 변환.
결과적으로 b는 해당 단어의 10개 감정 점수 리스트.
temp_value = [x + y for x, y in zip(temp_value, b)]
temp_value: 현재 문서에서 감정 점수를 누적하는 리스트.
b를 더해가며 문서 전체의 감정 점수를 계산.
🔍 이 코드의 목적
NRC 감성사전 기반 다중 감정 분석입니다.
단순히 긍·부정 점수만 계산하는 것이 아니라, 여러 감정 카테고리(기쁨, 슬픔, 분노 등)의 누적 점수를 구해서
문서의 감정 프로파일을 생성합니다.

---

[출처] 파이썬기반 SNS텍스트 데이터마이닝 개정판