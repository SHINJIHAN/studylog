{"title":"제 9장 회귀분석","markdown":{"yaml":{"title":"제 9장 회귀분석","format":"html"},"headingText":"01 기계 학습","containsRefs":false,"markdown":"\n\n> Reporting Date: October. 15, 2024\n\n한 변수가 다른 변수에 의해 설명 및 예측 과정을 분석하는 회귀분석에 대해 논의하고자 한다.\n\nMachine Learning\n\n데이터 기반으로 패턴과 규칙을 학습하고, 그 학습된 모델을 활용해\n미래 예측, 분류, 의사결정 등을 수행하는 알고리즘 및 방법론을\n연구하는 인공지능(AI)의 하위 분야이다.\n\n기계학습은  3 가지의 유형으로 구분된다.\n\n\n### 1 .  지도 학습\nSupervised Learning\n\n입력 변수 X 와 정답에 해당하는 타깃 변수 Y 가 함께 주어졌을 때,\nX 로부터 Y 를 예측하는 모델을 학습하는 방법이다.\n\n학습 과정에서는 데이터에 포함된 정답을 활용하여 입력과 출력 간의\n규칙을 찾고, 이를 기반으로 새로운 데이터에 대한 예측을 수행할 수 있다.\n\n크게 연속적인 값을 예측하는 회귀 문제와,\n특정 범주를 예측하는 분류 문제로 나눌 수 있다.\n\n대표적인 알고리즘으로는 선형 회귀, 로지스틱 회귀, 결정 트리,\nK-최근접 이웃(KNN), 서포트 벡터 머신(SVM), 신경망 등이 있다.\n\n\n\n### 2 .  비지도 학습\nUnsupervised Learning\n\n정답(타깃 변수) 없이 입력 데이터 X 만을 가지고\n데이터의 패턴, 구조, 분포를 학습하는 방법이다.\n\n주로 유사한 데이터들을 묶는 군집화,\n데이터의 차원을 줄여 본질적인 특성을 추출하는 차원 축소기법이 사용된다.\n\n대표적인 예로는 장바구니 분석(연관 규칙 학습), 다차원 척도법(MDS),\n주성분 분석(PCA), 요인 분석(FA) 등이 있다.\n\n\n\n### 3 .  강화 학습\nReinforcement Learning\n\n에이전트가 환경(Environment)과 상호작용하며,\n각 상태(State)에서 취할 수 있는 행동(Action)을 선택한다.\n\n그 결과로 보상(Reward)을 받으면서, 장기적으로 누적 보상을\n최대화할 수 있는 최적의 행동 방식을 학습하는 방법이다.\n\n정답 데이터가 주어지는 것이 아닌 시행착오를 통해\n스스로 전략을 개선하는 것이 특징입니다.\n\n이러한 특성 덕분에 강화 학습은 로봇 제어, 게임 인공지능,\n자율주행, 추천 시스템 등 순차적 의사결정 문제에 널리 활용된다.\n\n이 중 지도 학습에 속하는 회귀 모델을 중심으로 살펴보고자 한다.\n\n\n\"회귀\" 용어의 유래\n19세기 후반, 영국의 통계학자 프랜시스 골턴은 유전학 연구에서\n부모와 자녀의 키 상관관계를 조사하면서 처음으로 \"회귀\" 라는 용어를 사용하였다.\n\n그는 부모의 키가 평균보다 크거나 작은 경우, 자녀의 키가\n평균값으로 되돌아가는 경향을 발견하였고, 이를 회귀라고 설명하였다.\n즉, 자녀들의 키가 부모의 극단적인 키보다 평균에 가까워지는 현상을 의미한 것이다.\n\n이후 골턴의 연구를 바탕으로 칼 피어슨은 회귀 분석을 체계화하고\n수학적으로 확장하였으며, 선형 회귀의 공식과 상관계수 개념을 발전시켜\n오늘날 회귀는 통계학에서 중요한 분석 도구로 자리잡게 되었다.\n\n\n\n## 02 회귀 모델의 정의\n회귀 모델은 타겟 변수인 Y 를 예측하기 위해\n입력 변수 X 간의 관계를 학습하는 지도 학습의 한 유형이다.\n\n회귀 모델은 목적과 특성에 따라 5 가지 유형으로 구분된다.\n\n\n### 1 .  종속 변수의 개수에 따른 분류\n\n\n일변량 회귀\nUnivariate Regression\n\n하나의 종속 변수 Y 를 예측하기 위해\n입력 변수 X 와 Y 간의 관계를 모델링하는 방법이다.\n\n\n\n다변량 회귀\nMultivariate Regression\n\n여러 개의 종속 변수  Y1, Y2, …, Ym 를 동시에 예측하며,\n종속 변수 간의 상관관계와 입력 변수와의 관계를 함께 고려하여\n고차원적 관계를 모델링하는 것을 목표로 한다.\n\n\n\n### 2 .  두 변수 간의 관계에 따른 분류\n\n\n선형 회귀\nLinear Regression\n\n독립 변수와 종속 변수 사이의 관계가 선형적일 때 사용하는 모델로,\n종속 변수를 독립 변수들의 선형 결합으로 표현하며 회귀선을 직선으로 모델링한다.\n\n\n비선형 회귀\nNonlinear Regression\n\n두 변수 간의 관계가 비선형일 때 사용되며,\n다항 회귀나 곡선 형태의 수학적 함수를 통해 관계를 모델링한다.\n\n\n\n### 3 .  독립 변수의 개수에 따른 분류\n\n\n단순 회귀\nSimple Regression\n\n하나의 독립 변수 X를 사용하여 종속 변수 Y 를 예측하는 방법이다.\n\n\n다중 회귀\nMultiple Regression\n\n여러 독립 변수  X1, X2, …, Xp ​를 활용해 종속 변수 Y 를 예측하는 방법이다.\n\n현실적인 데이터 분석에서는 종속 변수에 영향을 미치는 요인이\n여러 개 존재하는 경우가 많기 떄문에 다중 회귀가 널리 활용된다.\n\n\n\n### 4 .  분산과 공분산\n\n\n분산\nVariance\n\n단일 변수의 산포 정도,\n즉 값들이 평균으로부터 얼마나 흩어져 있는지를 나타낸다.\n\n회귀 분석에서 종속 변수 Y 의 분산은 데이터가 얼마나 퍼져 있는지를 보여주며,\n분산이 작을수록 모델이 더 정밀한 예측을 할 가능성이 높다.\n\n\n공분산\nCovariance\n\n두 변수 간의 선형적 관계를 나타내는 지표로,\n두 변수가 함께 어떻게 변하는지를 측정한다.\n\n공분산이 양수이면 두 변수가 같은 방향으로 변하는 경향이 있고,\n음수이면 반대 방향으로 변하는 경향이 있다.\n\n다만 공분산 값 자체는 단위의 영향을 받아 크기 비교가 어려워,\n이를 표준화한 상관계수(Correlation Coefficient)가 자주 활용된다.\n\n\n### 5 .  로지스틱 회귀\nLogistic Regression\n\n종속 변수가 이진형(Binary)일 때 사용하는 회귀 기법이다.\n이진형 변수의 예로는 성공/실패, 생존/사망, Yes/No 등이 있다.\n\n선형 회귀처럼 값을 직접 예측하는 것이 아니라,\n특정 사건이 일어날 확률을 예측한다.\n\n예측된 확률은 0 과 1 사이의 값으로 표현되며,\n이를 기준으로 특정 클래스로 분류할 수 있다.\n\n이를 위해 선형 회귀 모형을 기반으로 한 결과를\n로그 오즈로 변환하고 로지스틱 함수를 적용하여 확률로 해석 가능하게 만든다.\n\n\n\n\n## 03 단순 회귀분석\nSimple Linear Regression\n\n하나의 독립 변수 X 와 하나의 종속 변수 Y 간의\n선형적 관계를 분석하는 기법이다.\n\n주로 두 변수 사이의 직선적 관계를 파악하고,\n이를 바탕으로 종속 변수를 예측하는 데 활용된다.\n\n예를 들어, 예약 건수와 판매량 간의 관계를 분석하거나,\n공부 시간과 시험 성적 간의 관계를 분석할 때 적용할 수 있다.\n\n\n### 1 .  절편\n통계적으로 유의하지 않더라도 직선의 위치를 결정하는\n수학적 요소이므로 회귀모형에는 일반적으로 포함하며,\n실질적인 해석의 초점은 독립변수의 효과를 나타내는 기울기 계수에 맞추어진다.\n\n\n### 2 .  오차\n통계 분석에서 회귀모형은 항상 일정 수준의 오차를 전제로 한다.\n만약 오차가 전혀 없다면 모든 데이터가 회귀직선 위에 위치하게 되지만,\n실제 데이터에서는 관측값이 직선에서 벗어나기 때문에 오차가 발생한다.\n\n실무에서는 다중선형회귀와 로지스틱 회귀가 가장 많이 활용되며,\n단순선형회귀는 주로 기초 개념 학습이나 기본 분석에 사용된다.\n\n단순선형회귀에서 중요한 점은 회귀계수를 추정하는 것으로,\n추정된 값은 보통 헷(^) 기호를 붙여 나타낸다.\n헷이 없는 기호는 모집단의 실제 모수를 의미한다.\n\n\n\n### 3 .  최소제곱법\nOrdinary Least Squares, OLS\n\n회귀분석에서 가장 널리 사용되는 회귀계수 추정 방법으로,\n잔차(실제값과 예측값의 차이)의 제곱 합을 최소화하여\n가장 적합한 회귀 직선을 구하는 기법이다.\n\n이를 통해 회귀 직선의 기울기(β₁)와 절편(β₀)을 추정할 수 있으며,\n단순 선형 회귀의 경우 공식은 다음과 같다.\n\n\n기울기 공식\n\n절편의 공식\n\n### 4 .  회귀계수(기울기) 검정\n회귀 분석에서 중요한 요소는 기울기이다.\n이는 독립 변수 X 가 종속 변수 Y 에 미치는 평균적 영향을 나타낸다.\n이 계수가 통계적으로 유의미한지 검증하기 위해  가설 검정을 수행한다.\n\n\n가설 설정\nHypothesis Formulation\n\n귀무가설(H₀) :  β = 0  (X 가 Y 에 영향을 주지 않는다)\n대립가설(H₁) :  β ≠ 0 (X 가 Y 에 유의한 영향을 준다)\n\n단순 선형 회귀에서는 회귀계수가 2 개(절편, 기울기)이므로 자유도는 n − 2 이다.\n여기서 n 은 표본의 크기(데이터 포인트 수)이다.\n\n\n\n검정 통계량\nTest Statistic\n\n회귀분석에서 검정 통계량(t - 통계량)은\n회귀계수가 0 인지 여부를 검정하는 데 사용된다.\n즉 독립변수와 종속변수 간의 관계가 유의미한지 검정할 수 있다.\n\n회귀분석에서 계수 추정치에 대한 검정은 주로 t-통계량을 활용하며,\n이는 표본의 크기가 충분히 클 경우 정규분포에 근사하지만\n원칙적으로는 자유도를 고려한 t - 분포를 따른다.\n\n\n이러한 검정을 위해 오차항은 평균이 0이고 분산이 일정하며,\n서로 독립적으로 정규분포를 따른다는 가정이 필요하다.\n\n이 가정을 바탕으로 회귀계수 β 에 대한 가설검정과 신뢰구간이 설정되며,\n연구자는 보통 귀무가설(계수=0)을 기각하고 대립가설(계수≠0)을 채택하기를 기대한다.\n\n\n\n기울기의 표준 오차\nStandard Error of the Slope\n\n회귀계수(기울기) 추정치의 변동성 또는 신뢰도를 나타내는 값이다.\n\n\n즉, 동일한 데이터 표본에서 회귀분석을 반복할 경우,\n추정된 기울기가 얼마나 변동할 수 있는지를 보여준다.\n\n표준 오차가 작을수록 기울기 추정치가 보다 정확하며,\n회귀계수 검정과 신뢰구간 계산에 활용된다.\n\n\n\n잔차의 표준편차\nStandard Error of the Estimate, σₑ\n\n회귀모형이 데이터를 얼마나 잘 설명하는지를 나타내는 지표로,\n단순 선형 회귀에서는 추정할 회귀계수가 2 개(절편과 기울기)이므로 자유도는 n − 2 가 된다.\n\n이 값을 이용하여 회귀계수의 t − 통계량을 계산하고,\n이를 기반으로 p − 값을 산출하여 귀무가설 기각 여부를 결정한다.\n\n일반적으로 p − 값이 0.05 보다 작으면 귀무가설을 기각하고,\n독립변수가 종속변수에 유의미한 영향을 준다고 판단한다.\n\n\n단순 회귀분석을 통해 독립 변수와 종속 변수 간의 관계를 파악할 수 있으며,\n최소제곱법(OLS)을 사용하여 회귀 직선을 추정한다.\n\n이후 회귀계수의 유의성을 검증하는 가설 검정과 자유도 계산을 통해,\n모델이 통계적으로 신뢰할 만한지 판단하고 분석 결과를 해석할 수 있다.\n\n\n단순 회귀분석 사례\n12개의 기업에 대해 1년 광고비와 매출액을 조사하여 얻은 것이다.\n\n```{python}\nimport pandas as pd\n\nurl = \"https://raw.githubusercontent.com/SHINJIHAN/advanced-bigdata/main/data/Sales.csv\"\nSales = pd.read_csv(url)\nSales.head()\n```\n\n```{python}\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.jointplot(x = 'Adver', y = 'Sales',\n             data = Sales, kind = 'reg')\n\nimport statsmodels.formula.api as smf\nSalesFit = smf.ols(formula = 'Sales ~ Adver',\n                   data = Sales).fit()\nSalesFit.summary()\n```\n\n한편, 결정계수(R^2)는 회귀모형이 종속변수의 변동을 얼마나 설명하는지를 나타내지만,\n값이 높다고 해서 항상 좋은 모델을 의미하는 것은 아니며 과적합 여부도 고려해야 한다.\n\n<그림1> 산점도와 회귀직선\n데이터를 직관적으로 이해하기 위해 선형 관계를 가정하고 직선 형태의 모델을 사용하는 경우가 많지만, 실제 데이터가 비선형 관계를 보이면 비선형 모델을 적용하기도 한다. 데이터가 선형인지 비선형인지는 산점도를 통해 시각적으로 확인할 수 있으며, 이때 산점도는 독립변수와 종속변수가 모두 연속형일 때 의미가 있다. 한편, 범주형 변수는 산점도로 바로 표현할 수 없지만, 회귀모델에서는 더미 변수로 변환하여 포함시킬 수 있으므로, 범주형 변수 역시 분석에 반영할 수 있다.\n\n```{python}\nsns.lmplot(x = 'Adver', y = 'Sales', data = Sales)\nsns.regplot(x = 'Adver', y = 'Sales', data = Sales, lowess = True)\n```\n\n반응변수에 대한 예측\n```{python}\npredictions = SalesFit.get_prediction()\npredictions.summary_frame(alpha = 0.05).round(3)\n\nSalesNew = pd.DataFrame({'Adver':[20, 30, 40]})\npredictions = SalesFit.get_prediction(SalesNew)\npredictions.summary_frame(alpha = 0.05).round(3)\n```\n\n## 04 잔차 분석\nResidual\n\n실제 관측값과 회귀 모형에 의해 추정된 예측값의 차이.\n\n이는 데이터 점과 회귀직선 사이의 수직 거리를 의미한다.\n회귀 모델이 데이터를 얼마나 잘 설명하는지를 나타내는 중요한 지표이며,\n잔차가 작을수록 모델의 적합도가 높음을 의미한다.\n\n따라서 잔차 분석을 통해 회귀 직선이 데이터를 얼마나 잘 표현하는지,\n그리고 모델 가정이 적절히 충족되는지를 평가할 수 있다.\n\n표준화잔차\nstandardized residuals\n\n표준화는 변수의 값을 평균 0 , 분산 1 로 변환하여\n서로 다른 척도를 가진 변수를 비교 가능하게 만드는 과정이다.\n\n이를 통해 특정 변수가 값의 범위가 크다는 이유만으로\n회귀분석에서 과도하게 영향을 미치는 문제를 완화할 수 있다.\n\n또한 잔차 분석 단계에서는 표준화 잔차나 학생화 잔차를 사용하여\n이상치를 탐지 및 모형의 적합성을 진단하기도 한다.\n\n```{python}\nFitted = SalesFit.predict()\nResidual = SalesFit.resid # 순수한 자기 잔차\nRStandard = SalesFit.resid_pearson # 표준화잔차\npd.DataFrame({'Fitted':Fitted, \n              'Residual':Residual,\n              'RStandard':RStandard})\n\nfig, ax = plt.subplots(figsize = (10, 8))\nsns.scatterplot(x = Fitted, y = RStandard)\nax.axhline(y = 0)\n```\n\n그러나 표준화는 잔차 간의 독립성을 보장하거나\n분산 불균형 문제를 근본적으로 해결하지는 못한다.\n\n독립성 문제는 주로 데이터의 자기상관에서 기인하며,\n이분산 문제는 가중회귀나 분산 안정화 변환과 같은 방법을 통해 보완해야 한다.\n\n따라서 표준화는 변수의 스케일을 맞추고 분석의 안정성을 높이는 데 중요한 역할을 하지만,\n모든 회귀 진단 문제를 해결하는 방법은 아니라는 점을 유념해야 한다.\n\n## 05 회귀 모델의 기본 가정\n회귀분석을 적용하기 위해서는 4 가지 기본 가정이 충족되어야 한다.\n\n### 1 .  선형성\nLinearity\n\n독립 변수와 종속 변수 간의 관계가 선형이어야 한다.\n이는 산점도 등의 그래프를 통해 확인할 수 있다.\n\n### 2 .  정규성\nNormality\n\n오차의 분포가 정규분포를 따라야 한다.\n이는 대부분의 데이터가 회귀선이라는 평균값 주변에 집중되어 있어야 함을 의미한다.\n\n```{python}\nimport numpy as np\nsns.distplot(RStandard, bins = 10)\n\nfrom scipy.stats import probplot\nprobplot(RStandard, plot = plt)\n```\n\n\n### 3 .  등분산성\nHomoscedasticity\n\n독립 변수의 값에 관계없이 오차의 분산이 일정해야 한다.\n이 가정들이 만족되지 않으면,모델의 예측 성능이 저하되거나 편향된 결과를 초래할 수 있다.\n따라서 회귀 분석을 수행할 때는 현실 문제에서 이러한 가정들이 만족되는지 먼저 확인해야 한다.\n가정이 충족되면, 독립 변수와 종속 변수 간의 관계에 따라 적합한 회귀 모델 유형을 선택하여 분석을 진행하면 된다.\n\n### 4 .  독립성\nIndependence\n\n관측값들 간에는 독립성이 유지되어야 한다.\n다중공선성일 경우, 각 독립 변수가 종속 변수에 미치는 영향을 개별적으로 평가하기가 어렵기 때문이다.\n\n```{python}\nfrom statsmodels.stats.stattools import durbin_watson\ndurbin_watson(RStandard) # 기준: 표준화잔차\n\nimport statsmodels.api as sm\nfig = plt.figure(figsize = (12, 8))\nfig = sm.graphics.plot_regress_exog(SalesFit, 'Adver', fig = fig)\n```\n\n---\n\n교제: 파이썬을 활용한 데이터 분석과 응용","srcMarkdownNoYaml":"\n\n> Reporting Date: October. 15, 2024\n\n한 변수가 다른 변수에 의해 설명 및 예측 과정을 분석하는 회귀분석에 대해 논의하고자 한다.\n\n## 01 기계 학습\nMachine Learning\n\n데이터 기반으로 패턴과 규칙을 학습하고, 그 학습된 모델을 활용해\n미래 예측, 분류, 의사결정 등을 수행하는 알고리즘 및 방법론을\n연구하는 인공지능(AI)의 하위 분야이다.\n\n기계학습은  3 가지의 유형으로 구분된다.\n\n\n### 1 .  지도 학습\nSupervised Learning\n\n입력 변수 X 와 정답에 해당하는 타깃 변수 Y 가 함께 주어졌을 때,\nX 로부터 Y 를 예측하는 모델을 학습하는 방법이다.\n\n학습 과정에서는 데이터에 포함된 정답을 활용하여 입력과 출력 간의\n규칙을 찾고, 이를 기반으로 새로운 데이터에 대한 예측을 수행할 수 있다.\n\n크게 연속적인 값을 예측하는 회귀 문제와,\n특정 범주를 예측하는 분류 문제로 나눌 수 있다.\n\n대표적인 알고리즘으로는 선형 회귀, 로지스틱 회귀, 결정 트리,\nK-최근접 이웃(KNN), 서포트 벡터 머신(SVM), 신경망 등이 있다.\n\n\n\n### 2 .  비지도 학습\nUnsupervised Learning\n\n정답(타깃 변수) 없이 입력 데이터 X 만을 가지고\n데이터의 패턴, 구조, 분포를 학습하는 방법이다.\n\n주로 유사한 데이터들을 묶는 군집화,\n데이터의 차원을 줄여 본질적인 특성을 추출하는 차원 축소기법이 사용된다.\n\n대표적인 예로는 장바구니 분석(연관 규칙 학습), 다차원 척도법(MDS),\n주성분 분석(PCA), 요인 분석(FA) 등이 있다.\n\n\n\n### 3 .  강화 학습\nReinforcement Learning\n\n에이전트가 환경(Environment)과 상호작용하며,\n각 상태(State)에서 취할 수 있는 행동(Action)을 선택한다.\n\n그 결과로 보상(Reward)을 받으면서, 장기적으로 누적 보상을\n최대화할 수 있는 최적의 행동 방식을 학습하는 방법이다.\n\n정답 데이터가 주어지는 것이 아닌 시행착오를 통해\n스스로 전략을 개선하는 것이 특징입니다.\n\n이러한 특성 덕분에 강화 학습은 로봇 제어, 게임 인공지능,\n자율주행, 추천 시스템 등 순차적 의사결정 문제에 널리 활용된다.\n\n이 중 지도 학습에 속하는 회귀 모델을 중심으로 살펴보고자 한다.\n\n\n\"회귀\" 용어의 유래\n19세기 후반, 영국의 통계학자 프랜시스 골턴은 유전학 연구에서\n부모와 자녀의 키 상관관계를 조사하면서 처음으로 \"회귀\" 라는 용어를 사용하였다.\n\n그는 부모의 키가 평균보다 크거나 작은 경우, 자녀의 키가\n평균값으로 되돌아가는 경향을 발견하였고, 이를 회귀라고 설명하였다.\n즉, 자녀들의 키가 부모의 극단적인 키보다 평균에 가까워지는 현상을 의미한 것이다.\n\n이후 골턴의 연구를 바탕으로 칼 피어슨은 회귀 분석을 체계화하고\n수학적으로 확장하였으며, 선형 회귀의 공식과 상관계수 개념을 발전시켜\n오늘날 회귀는 통계학에서 중요한 분석 도구로 자리잡게 되었다.\n\n\n\n## 02 회귀 모델의 정의\n회귀 모델은 타겟 변수인 Y 를 예측하기 위해\n입력 변수 X 간의 관계를 학습하는 지도 학습의 한 유형이다.\n\n회귀 모델은 목적과 특성에 따라 5 가지 유형으로 구분된다.\n\n\n### 1 .  종속 변수의 개수에 따른 분류\n\n\n일변량 회귀\nUnivariate Regression\n\n하나의 종속 변수 Y 를 예측하기 위해\n입력 변수 X 와 Y 간의 관계를 모델링하는 방법이다.\n\n\n\n다변량 회귀\nMultivariate Regression\n\n여러 개의 종속 변수  Y1, Y2, …, Ym 를 동시에 예측하며,\n종속 변수 간의 상관관계와 입력 변수와의 관계를 함께 고려하여\n고차원적 관계를 모델링하는 것을 목표로 한다.\n\n\n\n### 2 .  두 변수 간의 관계에 따른 분류\n\n\n선형 회귀\nLinear Regression\n\n독립 변수와 종속 변수 사이의 관계가 선형적일 때 사용하는 모델로,\n종속 변수를 독립 변수들의 선형 결합으로 표현하며 회귀선을 직선으로 모델링한다.\n\n\n비선형 회귀\nNonlinear Regression\n\n두 변수 간의 관계가 비선형일 때 사용되며,\n다항 회귀나 곡선 형태의 수학적 함수를 통해 관계를 모델링한다.\n\n\n\n### 3 .  독립 변수의 개수에 따른 분류\n\n\n단순 회귀\nSimple Regression\n\n하나의 독립 변수 X를 사용하여 종속 변수 Y 를 예측하는 방법이다.\n\n\n다중 회귀\nMultiple Regression\n\n여러 독립 변수  X1, X2, …, Xp ​를 활용해 종속 변수 Y 를 예측하는 방법이다.\n\n현실적인 데이터 분석에서는 종속 변수에 영향을 미치는 요인이\n여러 개 존재하는 경우가 많기 떄문에 다중 회귀가 널리 활용된다.\n\n\n\n### 4 .  분산과 공분산\n\n\n분산\nVariance\n\n단일 변수의 산포 정도,\n즉 값들이 평균으로부터 얼마나 흩어져 있는지를 나타낸다.\n\n회귀 분석에서 종속 변수 Y 의 분산은 데이터가 얼마나 퍼져 있는지를 보여주며,\n분산이 작을수록 모델이 더 정밀한 예측을 할 가능성이 높다.\n\n\n공분산\nCovariance\n\n두 변수 간의 선형적 관계를 나타내는 지표로,\n두 변수가 함께 어떻게 변하는지를 측정한다.\n\n공분산이 양수이면 두 변수가 같은 방향으로 변하는 경향이 있고,\n음수이면 반대 방향으로 변하는 경향이 있다.\n\n다만 공분산 값 자체는 단위의 영향을 받아 크기 비교가 어려워,\n이를 표준화한 상관계수(Correlation Coefficient)가 자주 활용된다.\n\n\n### 5 .  로지스틱 회귀\nLogistic Regression\n\n종속 변수가 이진형(Binary)일 때 사용하는 회귀 기법이다.\n이진형 변수의 예로는 성공/실패, 생존/사망, Yes/No 등이 있다.\n\n선형 회귀처럼 값을 직접 예측하는 것이 아니라,\n특정 사건이 일어날 확률을 예측한다.\n\n예측된 확률은 0 과 1 사이의 값으로 표현되며,\n이를 기준으로 특정 클래스로 분류할 수 있다.\n\n이를 위해 선형 회귀 모형을 기반으로 한 결과를\n로그 오즈로 변환하고 로지스틱 함수를 적용하여 확률로 해석 가능하게 만든다.\n\n\n\n\n## 03 단순 회귀분석\nSimple Linear Regression\n\n하나의 독립 변수 X 와 하나의 종속 변수 Y 간의\n선형적 관계를 분석하는 기법이다.\n\n주로 두 변수 사이의 직선적 관계를 파악하고,\n이를 바탕으로 종속 변수를 예측하는 데 활용된다.\n\n예를 들어, 예약 건수와 판매량 간의 관계를 분석하거나,\n공부 시간과 시험 성적 간의 관계를 분석할 때 적용할 수 있다.\n\n\n### 1 .  절편\n통계적으로 유의하지 않더라도 직선의 위치를 결정하는\n수학적 요소이므로 회귀모형에는 일반적으로 포함하며,\n실질적인 해석의 초점은 독립변수의 효과를 나타내는 기울기 계수에 맞추어진다.\n\n\n### 2 .  오차\n통계 분석에서 회귀모형은 항상 일정 수준의 오차를 전제로 한다.\n만약 오차가 전혀 없다면 모든 데이터가 회귀직선 위에 위치하게 되지만,\n실제 데이터에서는 관측값이 직선에서 벗어나기 때문에 오차가 발생한다.\n\n실무에서는 다중선형회귀와 로지스틱 회귀가 가장 많이 활용되며,\n단순선형회귀는 주로 기초 개념 학습이나 기본 분석에 사용된다.\n\n단순선형회귀에서 중요한 점은 회귀계수를 추정하는 것으로,\n추정된 값은 보통 헷(^) 기호를 붙여 나타낸다.\n헷이 없는 기호는 모집단의 실제 모수를 의미한다.\n\n\n\n### 3 .  최소제곱법\nOrdinary Least Squares, OLS\n\n회귀분석에서 가장 널리 사용되는 회귀계수 추정 방법으로,\n잔차(실제값과 예측값의 차이)의 제곱 합을 최소화하여\n가장 적합한 회귀 직선을 구하는 기법이다.\n\n이를 통해 회귀 직선의 기울기(β₁)와 절편(β₀)을 추정할 수 있으며,\n단순 선형 회귀의 경우 공식은 다음과 같다.\n\n\n기울기 공식\n\n절편의 공식\n\n### 4 .  회귀계수(기울기) 검정\n회귀 분석에서 중요한 요소는 기울기이다.\n이는 독립 변수 X 가 종속 변수 Y 에 미치는 평균적 영향을 나타낸다.\n이 계수가 통계적으로 유의미한지 검증하기 위해  가설 검정을 수행한다.\n\n\n가설 설정\nHypothesis Formulation\n\n귀무가설(H₀) :  β = 0  (X 가 Y 에 영향을 주지 않는다)\n대립가설(H₁) :  β ≠ 0 (X 가 Y 에 유의한 영향을 준다)\n\n단순 선형 회귀에서는 회귀계수가 2 개(절편, 기울기)이므로 자유도는 n − 2 이다.\n여기서 n 은 표본의 크기(데이터 포인트 수)이다.\n\n\n\n검정 통계량\nTest Statistic\n\n회귀분석에서 검정 통계량(t - 통계량)은\n회귀계수가 0 인지 여부를 검정하는 데 사용된다.\n즉 독립변수와 종속변수 간의 관계가 유의미한지 검정할 수 있다.\n\n회귀분석에서 계수 추정치에 대한 검정은 주로 t-통계량을 활용하며,\n이는 표본의 크기가 충분히 클 경우 정규분포에 근사하지만\n원칙적으로는 자유도를 고려한 t - 분포를 따른다.\n\n\n이러한 검정을 위해 오차항은 평균이 0이고 분산이 일정하며,\n서로 독립적으로 정규분포를 따른다는 가정이 필요하다.\n\n이 가정을 바탕으로 회귀계수 β 에 대한 가설검정과 신뢰구간이 설정되며,\n연구자는 보통 귀무가설(계수=0)을 기각하고 대립가설(계수≠0)을 채택하기를 기대한다.\n\n\n\n기울기의 표준 오차\nStandard Error of the Slope\n\n회귀계수(기울기) 추정치의 변동성 또는 신뢰도를 나타내는 값이다.\n\n\n즉, 동일한 데이터 표본에서 회귀분석을 반복할 경우,\n추정된 기울기가 얼마나 변동할 수 있는지를 보여준다.\n\n표준 오차가 작을수록 기울기 추정치가 보다 정확하며,\n회귀계수 검정과 신뢰구간 계산에 활용된다.\n\n\n\n잔차의 표준편차\nStandard Error of the Estimate, σₑ\n\n회귀모형이 데이터를 얼마나 잘 설명하는지를 나타내는 지표로,\n단순 선형 회귀에서는 추정할 회귀계수가 2 개(절편과 기울기)이므로 자유도는 n − 2 가 된다.\n\n이 값을 이용하여 회귀계수의 t − 통계량을 계산하고,\n이를 기반으로 p − 값을 산출하여 귀무가설 기각 여부를 결정한다.\n\n일반적으로 p − 값이 0.05 보다 작으면 귀무가설을 기각하고,\n독립변수가 종속변수에 유의미한 영향을 준다고 판단한다.\n\n\n단순 회귀분석을 통해 독립 변수와 종속 변수 간의 관계를 파악할 수 있으며,\n최소제곱법(OLS)을 사용하여 회귀 직선을 추정한다.\n\n이후 회귀계수의 유의성을 검증하는 가설 검정과 자유도 계산을 통해,\n모델이 통계적으로 신뢰할 만한지 판단하고 분석 결과를 해석할 수 있다.\n\n\n단순 회귀분석 사례\n12개의 기업에 대해 1년 광고비와 매출액을 조사하여 얻은 것이다.\n\n```{python}\nimport pandas as pd\n\nurl = \"https://raw.githubusercontent.com/SHINJIHAN/advanced-bigdata/main/data/Sales.csv\"\nSales = pd.read_csv(url)\nSales.head()\n```\n\n```{python}\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.jointplot(x = 'Adver', y = 'Sales',\n             data = Sales, kind = 'reg')\n\nimport statsmodels.formula.api as smf\nSalesFit = smf.ols(formula = 'Sales ~ Adver',\n                   data = Sales).fit()\nSalesFit.summary()\n```\n\n한편, 결정계수(R^2)는 회귀모형이 종속변수의 변동을 얼마나 설명하는지를 나타내지만,\n값이 높다고 해서 항상 좋은 모델을 의미하는 것은 아니며 과적합 여부도 고려해야 한다.\n\n<그림1> 산점도와 회귀직선\n데이터를 직관적으로 이해하기 위해 선형 관계를 가정하고 직선 형태의 모델을 사용하는 경우가 많지만, 실제 데이터가 비선형 관계를 보이면 비선형 모델을 적용하기도 한다. 데이터가 선형인지 비선형인지는 산점도를 통해 시각적으로 확인할 수 있으며, 이때 산점도는 독립변수와 종속변수가 모두 연속형일 때 의미가 있다. 한편, 범주형 변수는 산점도로 바로 표현할 수 없지만, 회귀모델에서는 더미 변수로 변환하여 포함시킬 수 있으므로, 범주형 변수 역시 분석에 반영할 수 있다.\n\n```{python}\nsns.lmplot(x = 'Adver', y = 'Sales', data = Sales)\nsns.regplot(x = 'Adver', y = 'Sales', data = Sales, lowess = True)\n```\n\n반응변수에 대한 예측\n```{python}\npredictions = SalesFit.get_prediction()\npredictions.summary_frame(alpha = 0.05).round(3)\n\nSalesNew = pd.DataFrame({'Adver':[20, 30, 40]})\npredictions = SalesFit.get_prediction(SalesNew)\npredictions.summary_frame(alpha = 0.05).round(3)\n```\n\n## 04 잔차 분석\nResidual\n\n실제 관측값과 회귀 모형에 의해 추정된 예측값의 차이.\n\n이는 데이터 점과 회귀직선 사이의 수직 거리를 의미한다.\n회귀 모델이 데이터를 얼마나 잘 설명하는지를 나타내는 중요한 지표이며,\n잔차가 작을수록 모델의 적합도가 높음을 의미한다.\n\n따라서 잔차 분석을 통해 회귀 직선이 데이터를 얼마나 잘 표현하는지,\n그리고 모델 가정이 적절히 충족되는지를 평가할 수 있다.\n\n표준화잔차\nstandardized residuals\n\n표준화는 변수의 값을 평균 0 , 분산 1 로 변환하여\n서로 다른 척도를 가진 변수를 비교 가능하게 만드는 과정이다.\n\n이를 통해 특정 변수가 값의 범위가 크다는 이유만으로\n회귀분석에서 과도하게 영향을 미치는 문제를 완화할 수 있다.\n\n또한 잔차 분석 단계에서는 표준화 잔차나 학생화 잔차를 사용하여\n이상치를 탐지 및 모형의 적합성을 진단하기도 한다.\n\n```{python}\nFitted = SalesFit.predict()\nResidual = SalesFit.resid # 순수한 자기 잔차\nRStandard = SalesFit.resid_pearson # 표준화잔차\npd.DataFrame({'Fitted':Fitted, \n              'Residual':Residual,\n              'RStandard':RStandard})\n\nfig, ax = plt.subplots(figsize = (10, 8))\nsns.scatterplot(x = Fitted, y = RStandard)\nax.axhline(y = 0)\n```\n\n그러나 표준화는 잔차 간의 독립성을 보장하거나\n분산 불균형 문제를 근본적으로 해결하지는 못한다.\n\n독립성 문제는 주로 데이터의 자기상관에서 기인하며,\n이분산 문제는 가중회귀나 분산 안정화 변환과 같은 방법을 통해 보완해야 한다.\n\n따라서 표준화는 변수의 스케일을 맞추고 분석의 안정성을 높이는 데 중요한 역할을 하지만,\n모든 회귀 진단 문제를 해결하는 방법은 아니라는 점을 유념해야 한다.\n\n## 05 회귀 모델의 기본 가정\n회귀분석을 적용하기 위해서는 4 가지 기본 가정이 충족되어야 한다.\n\n### 1 .  선형성\nLinearity\n\n독립 변수와 종속 변수 간의 관계가 선형이어야 한다.\n이는 산점도 등의 그래프를 통해 확인할 수 있다.\n\n### 2 .  정규성\nNormality\n\n오차의 분포가 정규분포를 따라야 한다.\n이는 대부분의 데이터가 회귀선이라는 평균값 주변에 집중되어 있어야 함을 의미한다.\n\n```{python}\nimport numpy as np\nsns.distplot(RStandard, bins = 10)\n\nfrom scipy.stats import probplot\nprobplot(RStandard, plot = plt)\n```\n\n\n### 3 .  등분산성\nHomoscedasticity\n\n독립 변수의 값에 관계없이 오차의 분산이 일정해야 한다.\n이 가정들이 만족되지 않으면,모델의 예측 성능이 저하되거나 편향된 결과를 초래할 수 있다.\n따라서 회귀 분석을 수행할 때는 현실 문제에서 이러한 가정들이 만족되는지 먼저 확인해야 한다.\n가정이 충족되면, 독립 변수와 종속 변수 간의 관계에 따라 적합한 회귀 모델 유형을 선택하여 분석을 진행하면 된다.\n\n### 4 .  독립성\nIndependence\n\n관측값들 간에는 독립성이 유지되어야 한다.\n다중공선성일 경우, 각 독립 변수가 종속 변수에 미치는 영향을 개별적으로 평가하기가 어렵기 때문이다.\n\n```{python}\nfrom statsmodels.stats.stattools import durbin_watson\ndurbin_watson(RStandard) # 기준: 표준화잔차\n\nimport statsmodels.api as sm\nfig = plt.figure(figsize = (12, 8))\nfig = sm.graphics.plot_regress_exog(SalesFit, 'Adver', fig = fig)\n```\n\n---\n\n교제: 파이썬을 활용한 데이터 분석과 응용"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"python":"C:/Users/sinji/anaconda3/envs/py310/python.exe","engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"ADA09.0.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.26","preview":{"host":"0.0.0.0","port":7809,"watch-inputs":true,"navigate":true,"browser":true},"theme":["zephyr","cosmo","brand"],"title":"제 9장 회귀분석"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}